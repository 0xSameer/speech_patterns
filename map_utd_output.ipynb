{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map ZRTools output to transcripts\n",
    "\n",
    "- Create modified .nodes file\n",
    "- Create mapping between es words, and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "feats_dict_fname = config['es']['feats_dict_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - identify the segment to which the node belongs\n",
    "\n",
    "Lookout for:\n",
    "1. Patterns that go across segment boundaries\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_segid(node_start, node_end, file_id, segment_map):\n",
    "    seg_id_list, start_time_list = zip(*sorted(segment_map[file_id].items(), key=lambda t:t[0]))\n",
    "\n",
    "    # Binary search to find segment where the node starts and ends in\n",
    "    # we subtract 1 as bisect returns the index where we can insert a value keeping\n",
    "    # the sort order. We do not expect it to be 0, as the node will always have a 0 or positive start\n",
    "    # time\n",
    "    seg_id_start = bisect.bisect(start_time_list, node_start)-1\n",
    "    s1 = seg_id_list[seg_id_start]\n",
    "    seg_id_end = bisect.bisect(start_time_list, node_end)-1\n",
    "    s2 = seg_id_list[seg_id_end]\n",
    "    \n",
    "    if seg_id_start == seg_id_end:\n",
    "        start = node_start - segment_map[file_id][s1]\n",
    "        end = node_end - segment_map[file_id][s1]\n",
    "        return s1, start, end, 0\n",
    "    else:\n",
    "        # Calculate which segment overlaps more\n",
    "        #print (file_id, node_start, node_end, seg_id, seg_id_start, seg_id_end, seg_id_list[seg_id_start-1], seg_id_list[seg_id_end-1])\n",
    "        if (segment_map[file_id][s2] - node_start) >= (node_end - segment_map[file_id][s2]):\n",
    "            shift_value = node_end - segment_map[file_id][s2]\n",
    "            start = node_start - segment_map[file_id][s1] - shift_value\n",
    "            end = segment_map[file_id][s2] - segment_map[file_id][s1]\n",
    "            print(\"More in s1\", start, end, shift_value)\n",
    "            return s1, start, end, 1\n",
    "        else:\n",
    "            shift_value = segment_map[file_id][s2] - node_start\n",
    "            start = 0\n",
    "            end = node_end - segment_map[file_id][s2] + shift_value\n",
    "            print(\"More in s2\", start, end, shift_value)\n",
    "            return s2, start, end, 1\n",
    "    print (file_id, node_start, node_end, seg_id_start, seg_id_end)\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More in s1 429 561 8\n",
      "('042.079', 429, 561, 1)\n",
      "('038.001', 0, 51, 0)\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "print(search_segid(20509, 20641, \"042\", segment_map))\n",
    "print(search_segid(0, 51, \"038\", segment_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - create a master_graph.segnodes file replacing nodes with their segment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_segmented_nodes(nodes_fname, segment_map, seg_nodes_fname):\n",
    "    total_errors = 0\n",
    "    with open(nodes_fname, \"r\") as nodes_f, open(seg_nodes_fname, \"w\") as segnodes_f:\n",
    "        for i, line in enumerate(nodes_f):\n",
    "            line_items = line.strip().split(None, 3)\n",
    "            file_id = line_items[0]\n",
    "            node_start, node_end = map(int, line_items[1:3])\n",
    "            try:\n",
    "                seg_id, seg_node_start, seg_node_end, e = search_segid(node_start, node_end, file_id, segment_map)\n",
    "                total_errors += e\n",
    "                outline = \"%s\\t%d\\t%d\\t%s\\n\" % (seg_id, seg_node_start, seg_node_end, line_items[3])\n",
    "                segnodes_f.write(outline)\n",
    "            except ValueError:\n",
    "                print(\"Incorrect line format at line: %d\\n%s\" % (i, line))\n",
    "                \n",
    "    print(\"Total nodes: %d\" % (i+1))\n",
    "    print(\"Total errors: %d\" % total_errors)\n",
    "    print(\"completed\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More in s2 0 57 7\n",
      "More in s1 341 399 25\n",
      "More in s1 292 348 21\n",
      "More in s1 303 360 6\n",
      "More in s1 91 144 24\n",
      "More in s2 0 60 6\n",
      "More in s2 0 53 24\n",
      "More in s2 0 51 5\n",
      "More in s2 0 55 6\n",
      "More in s2 0 52 12\n",
      "More in s1 93 146 14\n",
      "More in s2 0 51 8\n",
      "More in s2 0 54 16\n",
      "More in s2 0 57 3\n",
      "More in s2 0 55 1\n",
      "More in s1 303 360 6\n",
      "More in s1 457 526 19\n",
      "More in s1 469 526 7\n",
      "More in s2 0 51 1\n",
      "More in s2 0 57 1\n",
      "More in s1 239 302 3\n",
      "More in s1 159 212 10\n",
      "More in s1 20 75 4\n",
      "More in s1 92 150 5\n",
      "More in s2 0 51 18\n",
      "More in s1 416 468 3\n",
      "More in s1 482 534 1\n",
      "More in s1 36 88 4\n",
      "More in s2 0 51 1\n",
      "More in s2 0 54 7\n",
      "More in s1 102 154 3\n",
      "More in s2 0 51 12\n",
      "More in s2 0 51 19\n",
      "More in s2 0 58 1\n",
      "More in s2 0 53 24\n",
      "More in s2 0 53 12\n",
      "More in s2 0 53 12\n",
      "More in s2 0 85 13\n",
      "More in s2 0 71 1\n",
      "More in s2 0 51 13\n",
      "More in s2 0 54 6\n",
      "More in s2 0 59 8\n",
      "More in s2 0 56 3\n",
      "More in s2 0 63 5\n",
      "More in s2 0 60 5\n",
      "More in s2 0 52 18\n",
      "More in s2 0 56 1\n",
      "More in s2 0 56 4\n",
      "More in s2 0 51 1\n",
      "More in s2 0 57 2\n",
      "More in s2 0 51 1\n",
      "More in s1 127 179 0\n",
      "More in s2 0 54 1\n",
      "More in s1 222 276 9\n",
      "More in s1 346 398 0\n",
      "More in s1 223 276 22\n",
      "More in s1 344 398 5\n",
      "More in s2 0 55 26\n",
      "More in s1 -9 42 18\n",
      "More in s1 0 56 0\n",
      "More in s1 206 257 12\n",
      "More in s1 236 294 17\n",
      "More in s1 324 375 10\n",
      "More in s1 350 405 7\n",
      "More in s2 0 52 16\n",
      "More in s1 200 263 3\n",
      "More in s1 29 119 2\n",
      "More in s1 284 344 7\n",
      "More in s2 0 55 5\n",
      "More in s2 0 62 6\n",
      "More in s2 0 84 6\n",
      "More in s2 0 80 1\n",
      "More in s1 131 184 2\n",
      "More in s2 0 57 3\n",
      "More in s1 438 496 6\n",
      "More in s1 547 600 26\n",
      "More in s2 0 58 25\n",
      "More in s2 0 59 4\n",
      "More in s2 0 57 5\n",
      "More in s1 170 223 24\n",
      "More in s1 94 146 23\n",
      "More in s2 0 52 11\n",
      "More in s1 1019 1070 3\n",
      "More in s2 0 56 16\n",
      "More in s2 0 61 6\n",
      "More in s1 621 678 6\n",
      "More in s2 0 64 7\n",
      "More in s1 547 600 4\n",
      "More in s2 0 55 11\n",
      "More in s2 0 58 11\n",
      "More in s2 0 52 1\n",
      "More in s2 0 53 11\n",
      "More in s2 0 53 4\n",
      "More in s2 0 60 6\n",
      "More in s2 0 56 11\n",
      "More in s1 167 220 5\n",
      "More in s1 212 263 18\n",
      "More in s1 130 189 24\n",
      "More in s2 0 53 17\n",
      "More in s2 0 54 1\n",
      "More in s2 0 69 4\n",
      "More in s1 26 82 3\n",
      "More in s1 469 527 1\n",
      "More in s2 0 65 12\n",
      "More in s2 0 69 12\n",
      "More in s2 0 76 2\n",
      "More in s2 0 61 8\n",
      "More in s2 0 66 4\n",
      "More in s2 0 62 2\n",
      "More in s2 0 64 2\n",
      "More in s2 0 53 2\n",
      "More in s2 0 55 2\n",
      "More in s1 2 59 1\n",
      "More in s2 0 65 3\n",
      "More in s2 0 61 3\n",
      "More in s2 0 65 6\n",
      "More in s2 0 66 1\n",
      "More in s2 0 52 18\n",
      "More in s2 0 55 6\n",
      "More in s1 1063 1120 1\n",
      "More in s2 0 54 16\n",
      "More in s2 0 55 22\n",
      "More in s1 35 88 5\n",
      "More in s2 0 56 4\n",
      "More in s2 0 62 5\n",
      "More in s2 0 53 7\n",
      "More in s2 0 55 22\n",
      "More in s2 0 57 15\n",
      "More in s2 0 60 15\n",
      "More in s2 0 64 20\n",
      "More in s1 201 256 0\n",
      "More in s2 0 57 10\n",
      "More in s2 0 57 8\n",
      "More in s2 0 52 18\n",
      "More in s1 16 87 4\n",
      "More in s2 0 85 14\n",
      "More in s2 0 74 15\n",
      "More in s1 7 87 2\n",
      "More in s2 0 51 18\n",
      "More in s1 52 110 16\n",
      "More in s1 60 121 0\n",
      "More in s1 115 167 0\n",
      "More in s1 34 88 4\n",
      "More in s2 0 59 13\n",
      "More in s1 343 395 10\n",
      "More in s2 0 53 1\n",
      "More in s2 0 51 11\n",
      "More in s1 547 600 4\n",
      "More in s2 0 63 7\n",
      "More in s1 552 604 22\n",
      "More in s2 0 51 6\n",
      "More in s1 156 212 0\n",
      "More in s2 0 51 1\n",
      "More in s2 0 65 26\n",
      "More in s2 0 57 9\n",
      "More in s2 0 55 8\n",
      "More in s1 54 113 1\n",
      "More in s1 82 134 16\n",
      "More in s1 66 121 14\n",
      "More in s2 0 51 5\n",
      "More in s2 0 52 12\n",
      "More in s2 0 57 18\n",
      "More in s2 0 51 4\n",
      "More in s2 0 55 1\n",
      "More in s2 0 59 13\n",
      "More in s2 0 56 5\n",
      "More in s1 698 749 2\n",
      "More in s2 0 51 10\n",
      "More in s2 0 57 10\n",
      "More in s2 0 54 10\n",
      "More in s2 0 64 16\n",
      "More in s2 0 55 11\n",
      "More in s2 0 71 8\n",
      "More in s2 0 70 7\n",
      "More in s2 0 61 6\n",
      "More in s2 0 55 1\n",
      "More in s1 7 62 5\n",
      "More in s2 0 56 9\n",
      "More in s2 0 52 1\n",
      "More in s2 0 53 16\n",
      "More in s2 0 58 6\n",
      "More in s1 38 138 5\n",
      "More in s1 800 859 5\n",
      "More in s1 573 630 3\n",
      "More in s1 305 363 6\n",
      "More in s1 306 363 1\n",
      "More in s1 576 630 0\n",
      "More in s1 512 566 7\n",
      "More in s2 0 52 4\n",
      "More in s2 0 52 12\n",
      "More in s2 0 53 10\n",
      "More in s1 212 275 11\n",
      "More in s1 515 566 5\n",
      "More in s1 22 73 6\n",
      "More in s1 698 749 2\n",
      "More in s1 513 566 7\n",
      "More in s1 44 96 20\n",
      "More in s1 95 162 5\n",
      "More in s1 591 661 10\n",
      "More in s2 0 63 12\n",
      "More in s1 -10 50 15\n",
      "More in s1 -14 46 15\n",
      "More in s2 0 57 13\n",
      "More in s2 0 62 13\n",
      "More in s1 610 661 1\n",
      "More in s2 0 53 2\n",
      "More in s2 0 53 9\n",
      "More in s2 0 60 5\n",
      "More in s2 0 55 8\n",
      "More in s1 221 273 6\n",
      "More in s2 0 55 17\n",
      "More in s2 0 52 24\n",
      "More in s2 0 61 9\n",
      "More in s1 105 156 13\n",
      "More in s1 412 468 18\n",
      "More in s1 105 156 5\n",
      "More in s2 0 57 2\n",
      "More in s2 0 54 8\n",
      "More in s2 0 54 1\n",
      "More in s1 100 156 11\n",
      "More in s1 126 180 9\n",
      "More in s1 95 148 9\n",
      "More in s1 5 65 0\n",
      "More in s1 148 211 0\n",
      "More in s2 0 62 12\n",
      "More in s2 0 68 12\n",
      "More in s1 156 217 1\n",
      "More in s1 155 217 0\n",
      "More in s2 0 56 6\n",
      "More in s2 0 65 6\n",
      "More in s2 0 59 1\n",
      "More in s2 0 57 20\n",
      "More in s2 0 58 17\n",
      "More in s2 0 53 3\n",
      "More in s1 158 219 4\n",
      "More in s1 30 83 5\n",
      "More in s2 0 59 4\n",
      "More in s2 0 53 12\n",
      "More in s2 0 54 6\n",
      "More in s2 0 54 1\n",
      "More in s1 658 711 21\n",
      "More in s2 0 58 7\n",
      "More in s2 0 54 8\n",
      "More in s2 0 51 1\n",
      "More in s1 208 261 15\n",
      "More in s1 5 56 18\n",
      "More in s2 0 64 5\n",
      "More in s1 121 175 17\n",
      "More in s2 0 51 11\n",
      "More in s1 293 344 11\n",
      "More in s1 397 454 5\n",
      "More in s2 0 57 26\n",
      "More in s1 128 179 21\n",
      "More in s2 0 52 1\n",
      "More in s1 156 212 0\n",
      "More in s1 174 242 0\n",
      "More in s2 0 57 16\n",
      "More in s2 0 51 1\n",
      "More in s2 0 52 24\n",
      "More in s2 0 59 7\n",
      "More in s1 154 215 0\n",
      "More in s1 253 307 3\n",
      "More in s1 471 523 3\n",
      "More in s2 0 57 16\n",
      "More in s2 0 53 8\n",
      "More in s2 0 66 1\n",
      "More in s2 0 55 7\n",
      "More in s1 187 238 1\n",
      "More in s1 302 357 5\n",
      "More in s1 192 244 3\n",
      "More in s2 0 60 6\n",
      "More in s2 0 51 1\n",
      "More in s2 0 53 3\n",
      "More in s2 0 57 12\n",
      "More in s2 0 54 11\n",
      "More in s2 0 53 3\n",
      "More in s2 0 67 5\n",
      "More in s1 462 609 7\n",
      "More in s1 -2 142 3\n",
      "More in s2 0 59 4\n",
      "More in s2 0 51 4\n",
      "More in s2 0 51 1\n",
      "More in s2 0 51 1\n",
      "More in s1 622 676 0\n",
      "More in s1 192 244 3\n",
      "More in s1 302 357 5\n",
      "More in s1 -9 44 19\n",
      "More in s1 529 582 13\n",
      "More in s1 37 100 0\n",
      "More in s2 0 62 2\n",
      "More in s1 0 54 1\n",
      "More in s1 3 54 1\n",
      "More in s1 6 77 7\n",
      "More in s1 69 129 7\n",
      "More in s1 23 86 3\n",
      "More in s1 3 58 1\n",
      "More in s1 243 309 5\n",
      "More in s1 7 77 9\n",
      "More in s1 2 77 10\n",
      "More in s1 236 309 4\n",
      "More in s1 134 190 0\n",
      "More in s2 0 55 24\n",
      "More in s2 0 54 23\n",
      "More in s1 9 77 4\n",
      "More in s1 5 58 1\n",
      "More in s2 0 64 4\n",
      "More in s1 10 77 24\n",
      "More in s1 -2 54 23\n",
      "More in s1 30 86 17\n",
      "More in s2 0 51 2\n",
      "More in s2 0 57 1\n",
      "More in s1 52 110 16\n",
      "More in s2 0 51 1\n",
      "More in s2 0 51 11\n",
      "More in s2 0 51 21\n",
      "More in s2 0 69 8\n",
      "More in s2 0 68 6\n",
      "More in s2 0 58 3\n",
      "More in s1 238 290 5\n",
      "More in s2 0 70 3\n",
      "More in s2 0 55 1\n",
      "More in s1 416 468 3\n",
      "More in s1 115 173 3\n",
      "More in s2 0 51 3\n",
      "More in s2 0 55 10\n",
      "More in s1 241 294 5\n",
      "More in s2 0 53 5\n",
      "More in s2 0 53 6\n",
      "More in s1 128 184 5\n",
      "More in s2 0 54 26\n",
      "More in s1 -16 38 27\n",
      "More in s2 0 56 13\n",
      "More in s2 0 54 16\n",
      "More in s2 0 54 4\n",
      "More in s2 0 53 11\n",
      "More in s2 0 51 4\n",
      "More in s2 0 54 2\n",
      "More in s2 0 58 1\n",
      "More in s1 341 398 5\n",
      "More in s2 0 58 6\n",
      "More in s2 0 66 6\n",
      "More in s2 0 69 6\n",
      "More in s2 0 65 4\n",
      "More in s2 0 62 9\n",
      "More in s2 0 61 10\n",
      "More in s1 -1 50 1\n",
      "More in s2 0 73 3\n",
      "More in s2 0 72 1\n",
      "More in s1 -6 54 8\n",
      "More in s2 0 51 17\n",
      "More in s2 0 54 13\n",
      "More in s2 0 61 1\n",
      "More in s1 4 73 5\n",
      "More in s2 0 68 8\n",
      "More in s2 0 61 1\n",
      "More in s1 125 182 2\n",
      "More in s1 1159 1215 4\n",
      "More in s1 18 84 0\n",
      "More in s2 0 53 9\n",
      "More in s2 0 54 8\n",
      "More in s2 0 58 7\n",
      "More in s2 0 55 4\n",
      "More in s2 0 51 4\n",
      "More in s2 0 54 1\n",
      "More in s1 527 582 13\n",
      "More in s1 380 435 0\n",
      "More in s2 0 55 11\n",
      "More in s2 0 55 8\n",
      "More in s2 0 57 1\n",
      "More in s1 167 220 9\n",
      "More in s1 384 436 8\n",
      "More in s2 0 51 1\n",
      "More in s1 166 220 14\n",
      "More in s1 10 73 0\n",
      "More in s2 0 52 15\n",
      "More in s2 0 51 4\n",
      "More in s1 96 154 13\n",
      "More in s2 0 56 5\n",
      "More in s1 416 469 22\n",
      "More in s1 1769 1821 15\n",
      "More in s1 174 227 5\n",
      "More in s2 0 58 1\n",
      "More in s1 22 77 1\n",
      "More in s2 0 51 14\n",
      "More in s1 -16 36 19\n",
      "More in s2 0 60 6\n",
      "More in s2 0 53 10\n",
      "More in s1 126 181 26\n",
      "More in s1 -12 40 26\n",
      "More in s2 0 56 16\n",
      "More in s2 0 54 17\n",
      "More in s1 147 200 25\n",
      "More in s1 448 504 19\n",
      "More in s1 155 217 1\n",
      "More in s2 0 52 14\n",
      "More in s2 0 53 17\n",
      "More in s2 0 51 5\n",
      "More in s2 0 58 5\n",
      "More in s2 0 60 7\n",
      "More in s1 103 154 5\n",
      "More in s2 0 55 2\n",
      "More in s1 11 63 4\n",
      "More in s1 94 154 15\n",
      "More in s2 0 60 7\n",
      "More in s1 99 154 5\n",
      "More in s1 100 154 0\n",
      "More in s2 0 69 1\n",
      "More in s1 98 154 4\n",
      "More in s1 82 152 5\n",
      "More in s1 96 154 8\n",
      "More in s1 101 154 3\n",
      "More in s1 360 417 5\n",
      "More in s1 319 375 7\n",
      "More in s1 21 75 1\n",
      "More in s2 0 54 1\n",
      "More in s2 0 56 5\n",
      "More in s1 126 180 9\n",
      "More in s1 100 156 11\n",
      "More in s2 0 53 16\n",
      "More in s2 0 84 1\n",
      "More in s1 97 156 5\n",
      "More in s1 91 150 9\n",
      "More in s2 0 57 4\n",
      "More in s2 0 51 10\n",
      "More in s1 158 219 4\n",
      "More in s2 0 57 20\n",
      "More in s2 0 54 6\n",
      "More in s2 0 51 11\n",
      "More in s2 0 59 5\n",
      "More in s2 0 52 1\n",
      "More in s1 30 83 5\n",
      "More in s2 0 52 1\n",
      "More in s2 0 52 21\n",
      "More in s2 0 52 15\n",
      "More in s2 0 71 9\n",
      "More in s2 0 71 11\n",
      "More in s2 0 52 1\n",
      "More in s2 0 61 7\n",
      "More in s1 46 100 21\n",
      "More in s2 0 57 1\n",
      "More in s1 131 189 20\n",
      "More in s2 0 56 13\n",
      "More in s1 105 156 5\n",
      "More in s1 412 468 18\n",
      "More in s1 105 156 13\n",
      "More in s1 416 468 1\n",
      "More in s2 0 59 6\n",
      "More in s2 0 54 6\n",
      "More in s1 1460 1513 3\n",
      "More in s1 29 90 0\n",
      "More in s2 0 58 20\n",
      "More in s2 0 54 19\n",
      "More in s1 108 159 0\n",
      "More in s2 0 59 2\n",
      "More in s2 0 53 10\n",
      "More in s1 200 256 1\n",
      "More in s1 209 267 0\n",
      "More in s2 0 57 10\n",
      "More in s2 0 55 1\n",
      "More in s2 0 54 19\n",
      "More in s2 0 54 16\n",
      "More in s2 0 59 20\n",
      "More in s2 0 69 16\n",
      "More in s2 0 69 17\n",
      "More in s1 -5 50 5\n",
      "More in s1 -14 50 19\n",
      "More in s1 -15 42 17\n",
      "More in s1 987 1049 3\n",
      "More in s2 0 57 1\n",
      "More in s2 0 62 25\n",
      "More in s2 0 57 8\n",
      "More in s2 0 56 1\n",
      "More in s2 0 60 1\n",
      "More in s2 0 57 3\n",
      "More in s2 0 57 18\n",
      "More in s2 0 55 12\n",
      "More in s1 840 892 6\n",
      "More in s1 163 215 6\n",
      "More in s1 122 173 1\n",
      "More in s1 96 173 1\n",
      "More in s2 0 52 3\n",
      "More in s2 0 55 3\n",
      "More in s2 0 52 9\n",
      "More in s2 0 52 12\n",
      "More in s2 0 56 18\n",
      "More in s2 0 56 21\n",
      "More in s2 0 56 1\n",
      "More in s2 0 51 1\n",
      "More in s1 415 469 22\n",
      "More in s2 0 52 12\n",
      "More in s1 343 395 10\n",
      "More in s2 0 54 1\n",
      "More in s1 382 436 20\n",
      "More in s1 232 300 28\n",
      "More in s1 987 1049 3\n",
      "More in s1 -16 42 18\n",
      "More in s1 -14 50 19\n",
      "More in s1 780 834 0\n",
      "More in s1 385 436 5\n",
      "More in s1 272 323 0\n",
      "More in s2 0 57 4\n",
      "More in s1 23 77 1\n",
      "More in s1 34 88 4\n",
      "More in s1 218 273 24\n",
      "More in s2 0 51 11\n",
      "More in s1 384 436 8\n",
      "More in s2 0 54 17\n",
      "More in s1 107 158 25\n",
      "More in s2 0 51 10\n",
      "More in s2 0 60 6\n",
      "More in s2 0 51 11\n",
      "More in s2 0 58 5\n",
      "More in s2 0 61 25\n",
      "More in s1 841 892 8\n",
      "More in s1 291 342 2\n",
      "More in s2 0 56 1\n",
      "More in s2 0 52 1\n",
      "More in s1 28 79 1\n",
      "More in s1 33 94 5\n",
      "More in s1 90 146 1\n",
      "More in s1 324 375 10\n",
      "More in s1 234 294 19\n",
      "More in s1 205 257 13\n",
      "More in s1 650 702 1\n",
      "More in s1 0 56 0\n",
      "More in s2 0 53 14\n",
      "More in s2 0 55 1\n",
      "More in s1 315 375 6\n",
      "More in s2 0 51 12\n",
      "More in s1 751 807 1\n",
      "More in s1 21 75 3\n",
      "More in s2 0 56 3\n",
      "More in s2 0 57 26\n",
      "More in s1 397 454 5\n",
      "More in s1 293 344 11\n",
      "More in s2 0 56 1\n",
      "More in s2 0 51 1\n",
      "More in s1 97 154 17\n",
      "More in s1 319 375 7\n",
      "More in s1 30 86 18\n",
      "More in s2 0 57 11\n",
      "More in s1 350 405 7\n",
      "More in s2 0 52 1\n",
      "More in s2 0 53 4\n",
      "More in s2 0 53 1\n",
      "More in s1 56 108 5\n",
      "More in s2 0 80 1\n",
      "More in s2 0 66 2\n",
      "More in s1 80 131 11\n",
      "More in s1 20 75 13\n",
      "More in s2 0 68 26\n",
      "More in s2 0 58 28\n",
      "More in s2 0 57 2\n",
      "More in s1 1769 1821 15\n",
      "More in s2 0 55 1\n",
      "More in s1 53 105 4\n",
      "More in s1 98 153 0\n",
      "More in s1 31 94 7\n",
      "More in s1 95 153 1\n",
      "More in s1 60 111 1\n",
      "More in s2 0 51 22\n",
      "More in s1 379 432 14\n",
      "More in s2 0 56 4\n",
      "More in s1 216 267 8\n",
      "More in s1 -4 50 4\n",
      "More in s1 -1 50 8\n",
      "More in s1 46 100 8\n",
      "More in s2 0 51 1\n",
      "More in s1 268 322 1\n",
      "More in s1 -4 50 4\n",
      "More in s1 593 653 3\n",
      "More in s1 -1 56 6\n",
      "More in s1 -2 52 5\n",
      "More in s1 266 322 3\n",
      "More in s2 0 62 6\n",
      "More in s2 0 60 1\n",
      "More in s2 0 62 6\n",
      "More in s2 0 54 8\n",
      "More in s1 1 58 8\n",
      "More in s1 -13 50 13\n",
      "More in s2 0 61 7\n",
      "More in s1 746 802 0\n",
      "More in s2 0 53 4\n",
      "More in s2 0 51 23\n",
      "More in s1 588 643 2\n",
      "More in s2 0 52 7\n",
      "More in s2 0 55 2\n",
      "More in s2 0 52 23\n",
      "More in s2 0 54 12\n",
      "More in s2 0 53 6\n",
      "More in s2 0 58 6\n",
      "More in s1 64 115 1\n",
      "More in s1 0 65 0\n",
      "More in s1 5 56 1\n",
      "More in s2 0 60 6\n",
      "More in s2 0 57 1\n",
      "More in s1 104 157 4\n",
      "More in s2 0 52 23\n",
      "More in s2 0 55 3\n",
      "More in s1 36 123 3\n",
      "More in s2 0 56 12\n",
      "More in s2 0 54 13\n",
      "More in s1 122 180 4\n",
      "More in s2 0 57 14\n",
      "More in s2 0 60 18\n",
      "More in s2 0 67 23\n",
      "More in s2 0 56 20\n",
      "Total nodes: 56162\n",
      "Total errors: 607\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "create_segmented_nodes(nodes_fname, segment_map, seg_nodes_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - find transcript words corresponding to node start and end times\n",
    "\n",
    "Create node dictionary:\n",
    "    - node id\n",
    "    - file id\n",
    "    - seg id\n",
    "    - start time\n",
    "    - end time\n",
    "    - es words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_align_words_for_node(align_words_list, start, end):\n",
    "    #display(align_words_list, start, end)\n",
    "    words, start_times, end_times = zip(*(align_words_list))\n",
    "    start_i = bisect.bisect(end_times, start)\n",
    "    # end index will be 1 beyond the actual end\n",
    "    end_i = bisect.bisect(start_times, end)\n",
    "    return words[start_i:end_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VAMOS', 'A', 'VER')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('ESTA', 'MECHITA')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(find_align_words_for_node(align_dict[\"001\"][\"001.224\"][\"es\"], 191, 246))\n",
    "display(find_align_words_for_node(align_dict[\"001\"][\"001.274\"][\"es\"], 45, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_nodes_align(seg_nodes_fname, segment_map, align_dict):\n",
    "    total_errors = 0\n",
    "    nodes_dict = {}\n",
    "    with open(seg_nodes_fname, \"r\") as seg_nodes_f:\n",
    "        for nid, line in enumerate(seg_nodes_f, start=1):\n",
    "            line_items = line.strip().split()\n",
    "            file_id = line_items[0].split('.')[0]\n",
    "            seg_id = line_items[0]\n",
    "            start_t, end_t = map(int, line_items[1:3])\n",
    "            if seg_id in align_dict[file_id]:\n",
    "                es_w = find_align_words_for_node(align_dict[file_id][seg_id]['es'], start_t, end_t)\n",
    "                if len(align_dict[file_id][seg_id]['es_cnt']) > 0:\n",
    "                    es_cnt_w = find_align_words_for_node(align_dict[file_id][seg_id]['es_cnt'], start_t, end_t)\n",
    "                else:\n",
    "                    es_cnt_w = tuple()\n",
    "                    total_errors += 1\n",
    "            else:\n",
    "                es_w = tuple()\n",
    "                total_errors += 1\n",
    "            \n",
    "            nodes_dict[nid] = Node(file_id, seg_id, start_t, end_t, es_w, es_cnt_w)\n",
    "            if nid % 100000 == 0:\n",
    "                print('reading node %d' % nid)\n",
    "    print(\"finished reading %d nodes\" % nid)\n",
    "    print('No content words found for %d nodes' % total_errors)\n",
    "    return nodes_dict\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading 56162 nodes\n",
      "No content words found for 72 nodes\n"
     ]
    }
   ],
   "source": [
    "nodes_dict = map_nodes_align(seg_nodes_fname, segment_map, align_dict)\n",
    "pickle.dump(nodes_dict, open(nodes_dict_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges - create a valid edges file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_edges():\n",
    "    olap_dict = {}\n",
    "    pairs_list = []\n",
    "    # process clusters file\n",
    "    with open(config['es']['edges_olap_fname'], \"r\") as in_f:\n",
    "        for i, line in enumerate(in_f):\n",
    "            line_items = map(int, line.strip().split())\n",
    "            olap_dict[line_items[0]] = line_items[0]\n",
    "            if len(line_items) > 1:\n",
    "                for j in line_items[1:]:\n",
    "                    olap_dict[j] = line_items[0]\n",
    "\n",
    "    # Read edges dict\n",
    "    with open(config['es']['edges_utd_fname'], \"r\") as in_f:\n",
    "        for i, line in enumerate(in_f):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Processing line: %d\" % (i+1))\n",
    "            line_items = line.strip().split()\n",
    "            node_1 = int(line_items[0])\n",
    "            node_2 = int(line_items[1])\n",
    "            if node_1 not in olap_dict:\n",
    "                olap_dict[node_1] = node_1\n",
    "            if node_2 not in olap_dict:\n",
    "                olap_dict[node_2] = node_2\n",
    "            dtw_val = float(line_items[2]) / 1000.0\n",
    "\n",
    "            node_1 = olap_dict[node_1]\n",
    "            node_2 = olap_dict[node_2]\n",
    "\n",
    "            # Add to pairs list as a tuple\n",
    "            pairs_list.append((min(node_1, node_2), max(node_1, node_2), dtw_val))\n",
    "\n",
    "\n",
    "    print(\"Finished - reading edges ...\")\n",
    "    print(\"Removing duplicates in pairs list\")\n",
    "    set_pairs = list(set(pairs_list))\n",
    "    print(\"Set length: %d and List length: %d\" %(len(set_pairs), len(pairs_list)))\n",
    "    pairs_list = sorted(list(set_pairs))\n",
    "    with open(config['es']['edges_score_fname'], \"w\") as out_f:\n",
    "        for (n1, n2, dtw) in set_pairs:\n",
    "            out_line = \"%d\\t%d\\t%.3f\\n\" % (n1, n2, dtw)\n",
    "            out_f.write(out_line)\n",
    "    pickle.dump(set_pairs, open(config['es']['score_pairs_fname'], \"wb\"))\n",
    "    print(\"finished writing edges\")\n",
    "    \n",
    "    # validity check for duplicates\n",
    "    set_nodes_only = [(n1,n2) for n1, n2, dtw in set_pairs]\n",
    "    if len(set_pairs) != len(set_nodes_only):\n",
    "        raise IOError\n",
    "    return pairs_list   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing line: 1\n",
      "Processing line: 1001\n",
      "Processing line: 2001\n",
      "Processing line: 3001\n",
      "Processing line: 4001\n",
      "Processing line: 5001\n",
      "Processing line: 6001\n",
      "Processing line: 7001\n",
      "Processing line: 8001\n",
      "Processing line: 9001\n",
      "Processing line: 10001\n",
      "Processing line: 11001\n",
      "Processing line: 12001\n",
      "Processing line: 13001\n",
      "Processing line: 14001\n",
      "Processing line: 15001\n",
      "Processing line: 16001\n",
      "Processing line: 17001\n",
      "Processing line: 18001\n",
      "Processing line: 19001\n",
      "Processing line: 20001\n",
      "Processing line: 21001\n",
      "Processing line: 22001\n",
      "Processing line: 23001\n",
      "Processing line: 24001\n",
      "Processing line: 25001\n",
      "Processing line: 26001\n",
      "Processing line: 27001\n",
      "Processing line: 28001\n",
      "Finished - reading edges ...\n",
      "Removing duplicates in pairs list\n",
      "Set length: 25501 and List length: 28081\n",
      "finished writing edges\n"
     ]
    }
   ],
   "source": [
    "valid_pairs = read_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clusters\n",
    "\n",
    "- Save list of clusters\n",
    "- Generate bag of cluster ids for each segment\n",
    "    - use nodes per segment as replace with cluster id\n",
    "    - if no node found, use cluster id -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17394\n"
     ]
    }
   ],
   "source": [
    "segids = []\n",
    "for fid in segment_map:\n",
    "    segids.extend(segment_map[fid].keys())\n",
    "print(len(segids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_clusters(clusters_utd_fname):\n",
    "    clusters = []\n",
    "    with open(clusters_utd_fname, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            try:\n",
    "                nodes = map(int, line.strip().split())\n",
    "                clusters.append(nodes)\n",
    "            except:\n",
    "                print(line)                    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = load_clusters(clusters_utd_fname)\n",
    "pickle.dump(clusters, open(clusters_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pseudowords_for_segments(segment_map, nodes_dict, clusters, feats_fname, feats_dict_fname):\n",
    "    feats_dict = {}\n",
    "    total_errors = 0\n",
    "    display_den = len(clusters) // 10\n",
    "    \n",
    "    for clid, nodes in enumerate(clusters):\n",
    "        if clid % display_den == 0:\n",
    "            print('processing cluster %d out of %d' % (clid, len(clusters)))\n",
    "        for nid in nodes:\n",
    "            node = nodes_dict[nid]\n",
    "            if node.seg not in feats_dict:\n",
    "                feats_dict[node.seg] = []\n",
    "            feats_dict[node.seg].append(str(clid))\n",
    "    \n",
    "    print(\"total clusters: %d\" % clid)\n",
    "    # Get complete list of segment ids\n",
    "    segids = []\n",
    "    for fid in segment_map:\n",
    "        segids.extend(segment_map[fid].keys())\n",
    "    \n",
    "    with open(feats_fname, \"w\") as out_f:\n",
    "        for seg_id in sorted(segids):\n",
    "            # adding -1 for missing pseudotext\n",
    "            if seg_id not in feats_dict:\n",
    "                #outline = \"-1\\n\"\n",
    "                total_errors += 1\n",
    "                feats_dict[seg_id] = ['-1']\n",
    "            \n",
    "            outline = \" \".join(map(str,sorted(feats_dict[seg_id])))\n",
    "            outline = outline.strip() + \"\\n\"\n",
    "            out_f.write(outline)\n",
    "            \n",
    "    print(\"Finished writing features file: %s\" % os.path.basename(feats_fname))\n",
    "    print(\"Writing to file: %s\" % os.path.basename(feats_dict_fname))\n",
    "    pickle.dump(feats_dict, open(feats_dict_fname, \"wb\"))\n",
    "    print(\"Psuedowords not found for: %d segments, out of total: %d segments\" % (total_errors, len(segids)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing cluster 0 out of 15089\n",
      "processing cluster 1508 out of 15089\n",
      "processing cluster 3016 out of 15089\n",
      "processing cluster 4524 out of 15089\n",
      "processing cluster 6032 out of 15089\n",
      "processing cluster 7540 out of 15089\n",
      "processing cluster 9048 out of 15089\n",
      "processing cluster 10556 out of 15089\n",
      "processing cluster 12064 out of 15089\n",
      "processing cluster 13572 out of 15089\n",
      "processing cluster 15080 out of 15089\n",
      "total clusters: 15088\n",
      "Finished writing features file: pseudowords.feats\n",
      "Writing to file: pseudowords.dict\n",
      "Psuedowords not found for: 8896 segments, out of total: 17394 segments\n"
     ]
    }
   ],
   "source": [
    "generate_pseudowords_for_segments(segment_map, nodes_dict, clusters, feats_fname, feats_dict_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'../../../ZRTools/exp/callhome/matches/config0.88-0.90-0.80-50/pseudowords.dict'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_dict_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
