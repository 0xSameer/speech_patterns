{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map ZRTools output to transcripts\n",
    "\n",
    "- Create modified .nodes file\n",
    "- Create mapping between es words, and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "feats_dict_fname = config['es']['feats_dict_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - identify the segment to which the node belongs\n",
    "\n",
    "Lookout for:\n",
    "1. Patterns that go across segment boundaries\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_segid(node_start, node_end, file_id, segment_map):\n",
    "    seg_id_list, start_time_list = zip(*sorted(segment_map[file_id].items(), key=lambda t:t[0]))\n",
    "\n",
    "    # Binary search to find segment where the node starts and ends in\n",
    "    # we subtract 1 as bisect returns the index where we can insert a value keeping\n",
    "    # the sort order. We do not expect it to be 0, as the node will always have a 0 or positive start\n",
    "    # time\n",
    "    seg_id_start = bisect.bisect(start_time_list, node_start)-1\n",
    "    s1 = seg_id_list[seg_id_start]\n",
    "    seg_id_end = bisect.bisect(start_time_list, node_end)-1\n",
    "    s2 = seg_id_list[seg_id_end]\n",
    "    \n",
    "    if seg_id_start == seg_id_end:\n",
    "        start = node_start - segment_map[file_id][s1]\n",
    "        end = node_end - segment_map[file_id][s1]\n",
    "        return s1, start, end, 0\n",
    "    else:\n",
    "        # Calculate which segment overlaps more\n",
    "        #print (file_id, node_start, node_end, seg_id, seg_id_start, seg_id_end, seg_id_list[seg_id_start-1], seg_id_list[seg_id_end-1])\n",
    "        if (segment_map[file_id][s2] - node_start) >= (node_end - segment_map[file_id][s2]):\n",
    "            shift_value = node_end - segment_map[file_id][s2]\n",
    "            start = node_start - segment_map[file_id][s1] - shift_value\n",
    "            end = segment_map[file_id][s2] - segment_map[file_id][s1]\n",
    "            print(\"More in s1\", start, end, shift_value)\n",
    "            return s1, start, end, 1\n",
    "        else:\n",
    "            shift_value = segment_map[file_id][s2] - node_start\n",
    "            start = 0\n",
    "            end = node_end - segment_map[file_id][s2] + shift_value\n",
    "            print(\"More in s2\", start, end, shift_value)\n",
    "            return s2, start, end, 1\n",
    "    print (file_id, node_start, node_end, seg_id_start, seg_id_end)\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More in s1 429 561 8\n",
      "('042.079', 429, 561, 1)\n",
      "('038.001', 0, 51, 0)\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "print(search_segid(20509, 20641, \"042\", segment_map))\n",
    "print(search_segid(0, 51, \"038\", segment_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - create a master_graph.segnodes file replacing nodes with their segment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_segmented_nodes(nodes_fname, segment_map, seg_nodes_fname):\n",
    "    total_errors = 0\n",
    "    with open(nodes_fname, \"r\") as nodes_f, open(seg_nodes_fname, \"w\") as segnodes_f:\n",
    "        for i, line in enumerate(nodes_f):\n",
    "            line_items = line.strip().split(None, 3)\n",
    "            file_id = line_items[0]\n",
    "            node_start, node_end = map(int, line_items[1:3])\n",
    "            try:\n",
    "                seg_id, seg_node_start, seg_node_end, e = search_segid(node_start, node_end, file_id, segment_map)\n",
    "                total_errors += e\n",
    "                outline = \"%s\\t%d\\t%d\\t%s\\n\" % (seg_id, seg_node_start, seg_node_end, line_items[3])\n",
    "                segnodes_f.write(outline)\n",
    "            except ValueError:\n",
    "                print(\"Incorrect line format at line: %d\\n%s\" % (i, line))\n",
    "                \n",
    "    print(\"Total nodes: %d\" % (i+1))\n",
    "    print(\"Total errors: %d\" % total_errors)\n",
    "    print(\"completed\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More in s2 0 52 4\n",
      "More in s2 0 46 18\n",
      "More in s2 0 44 1\n",
      "More in s2 0 43 13\n",
      "More in s1 434 476 10\n",
      "More in s1 0 56 0\n",
      "More in s2 0 47 1\n",
      "More in s1 69 117 4\n",
      "More in s1 239 280 18\n",
      "More in s2 0 44 5\n",
      "More in s1 21 67 1\n",
      "More in s1 43 91 2\n",
      "More in s1 801 851 3\n",
      "More in s2 0 41 1\n",
      "More in s2 0 51 7\n",
      "More in s2 0 50 10\n",
      "More in s2 0 45 6\n",
      "More in s2 0 45 11\n",
      "More in s2 0 121 9\n",
      "More in s2 0 51 6\n",
      "More in s1 227 276 24\n",
      "More in s2 0 44 1\n",
      "More in s2 0 43 12\n",
      "More in s2 0 53 4\n",
      "More in s1 1 51 4\n",
      "More in s2 0 42 12\n",
      "More in s1 204 252 2\n",
      "More in s2 0 47 18\n",
      "More in s1 454 502 2\n",
      "More in s2 0 44 1\n",
      "More in s2 0 47 8\n",
      "More in s2 0 45 9\n",
      "More in s2 0 45 6\n",
      "More in s1 487 528 18\n",
      "More in s1 77 126 15\n",
      "More in s1 8 54 0\n",
      "More in s2 0 47 6\n",
      "More in s2 0 46 8\n",
      "More in s2 0 45 4\n",
      "More in s2 0 48 3\n",
      "More in s1 483 528 19\n",
      "More in s2 0 43 9\n",
      "More in s2 0 47 4\n",
      "More in s2 0 43 10\n",
      "More in s2 0 43 3\n",
      "More in s1 13 54 3\n",
      "More in s2 0 43 15\n",
      "More in s2 0 45 1\n",
      "More in s2 0 43 1\n",
      "More in s2 0 43 16\n",
      "More in s2 0 49 15\n",
      "More in s1 68 110 3\n",
      "More in s2 0 59 2\n",
      "More in s1 323 369 19\n",
      "More in s1 359 401 4\n",
      "More in s2 0 43 7\n",
      "More in s2 0 44 3\n",
      "More in s2 0 50 13\n",
      "More in s2 0 42 13\n",
      "More in s2 0 43 12\n",
      "More in s1 -1 44 20\n",
      "More in s1 22 69 3\n",
      "More in s2 0 42 18\n",
      "More in s1 74 125 2\n",
      "More in s2 0 45 5\n",
      "More in s2 0 50 1\n",
      "More in s2 0 43 2\n",
      "More in s1 -7 38 11\n",
      "More in s1 251 296 10\n",
      "More in s1 108 155 4\n",
      "More in s2 0 44 1\n",
      "More in s1 431 476 12\n",
      "More in s2 0 52 6\n",
      "More in s2 0 44 3\n",
      "More in s2 0 43 11\n",
      "More in s2 0 44 12\n",
      "More in s2 0 44 1\n",
      "More in s2 0 48 1\n",
      "More in s2 0 46 22\n",
      "More in s2 0 48 17\n",
      "More in s2 0 46 16\n",
      "More in s2 0 46 4\n",
      "More in s2 0 43 19\n",
      "More in s1 -8 34 20\n",
      "More in s1 59 104 18\n",
      "More in s2 0 43 3\n",
      "More in s2 0 43 4\n",
      "More in s1 1650 1700 4\n",
      "More in s2 0 44 4\n",
      "More in s2 0 49 9\n",
      "More in s2 0 45 2\n",
      "More in s1 239 282 2\n",
      "More in s2 0 44 6\n",
      "More in s2 0 42 1\n",
      "More in s1 9 58 0\n",
      "More in s2 0 46 1\n",
      "More in s2 0 44 6\n",
      "More in s1 107 154 12\n",
      "More in s1 3 46 13\n",
      "More in s1 108 155 2\n",
      "More in s1 69 117 4\n",
      "More in s1 396 438 14\n",
      "More in s1 350 396 13\n",
      "More in s2 0 51 11\n",
      "More in s2 0 44 6\n",
      "More in s2 0 44 4\n",
      "More in s2 0 43 2\n",
      "More in s1 255 307 3\n",
      "More in s2 0 43 1\n",
      "More in s2 0 41 8\n",
      "More in s1 114 156 13\n",
      "More in s1 45 91 9\n",
      "More in s1 221 273 5\n",
      "More in s2 0 55 3\n",
      "More in s2 0 62 3\n",
      "More in s2 0 59 3\n",
      "More in s2 0 61 4\n",
      "More in s2 0 43 6\n",
      "More in s2 0 46 10\n",
      "More in s1 26 69 9\n",
      "More in s2 0 48 2\n",
      "More in s2 0 45 15\n",
      "More in s1 312 369 0\n",
      "More in s2 0 50 18\n",
      "More in s2 0 41 1\n",
      "More in s1 25 69 5\n",
      "More in s2 0 45 18\n",
      "More in s1 5 54 21\n",
      "More in s2 0 42 12\n",
      "More in s1 168 214 3\n",
      "More in s1 113 159 14\n",
      "More in s1 68 110 5\n",
      "More in s1 466 507 7\n",
      "More in s2 0 55 13\n",
      "More in s2 0 53 1\n",
      "More in s1 88 129 5\n",
      "More in s2 0 42 4\n",
      "More in s2 0 56 6\n",
      "More in s1 86 134 2\n",
      "More in s2 0 42 8\n",
      "More in s2 0 45 16\n",
      "More in s2 0 50 15\n",
      "More in s2 0 43 19\n",
      "More in s1 274 319 0\n",
      "More in s2 0 41 10\n",
      "More in s2 0 46 1\n",
      "More in s1 153 196 5\n",
      "More in s2 0 51 23\n",
      "More in s2 0 42 17\n",
      "More in s2 0 42 3\n",
      "More in s1 108 150 1\n",
      "More in s2 0 49 4\n",
      "More in s1 207 257 1\n",
      "More in s2 0 47 8\n",
      "More in s2 0 63 1\n",
      "More in s1 248 292 0\n",
      "More in s1 246 292 0\n",
      "More in s2 0 50 4\n",
      "More in s1 246 292 0\n",
      "More in s2 0 44 12\n",
      "More in s1 254 321 15\n",
      "More in s2 0 53 10\n",
      "More in s1 265 321 19\n",
      "More in s2 0 45 1\n",
      "More in s1 264 321 9\n",
      "More in s1 13 54 7\n",
      "More in s1 0 48 8\n",
      "More in s1 231 292 0\n",
      "More in s1 247 292 0\n",
      "More in s1 271 321 14\n",
      "More in s2 0 44 1\n",
      "More in s2 0 50 9\n",
      "More in s1 247 292 0\n",
      "More in s2 0 55 9\n",
      "More in s1 264 321 1\n",
      "More in s1 247 292 0\n",
      "More in s1 272 321 4\n",
      "More in s2 0 53 2\n",
      "More in s2 0 50 1\n",
      "More in s1 269 321 10\n",
      "More in s1 260 321 4\n",
      "More in s2 0 48 1\n",
      "More in s2 0 46 1\n",
      "More in s1 253 321 12\n",
      "More in s2 0 46 3\n",
      "More in s2 0 43 1\n",
      "More in s2 0 42 8\n",
      "More in s2 0 43 6\n",
      "More in s2 0 49 6\n",
      "More in s2 0 42 4\n",
      "More in s2 0 43 15\n",
      "More in s2 0 46 11\n",
      "More in s2 0 43 1\n",
      "More in s1 213 257 0\n",
      "More in s1 112 165 2\n",
      "More in s2 0 55 23\n",
      "More in s1 73 126 15\n",
      "More in s2 0 56 6\n",
      "More in s2 0 49 12\n",
      "More in s2 0 41 1\n",
      "More in s2 0 57 1\n",
      "More in s1 1938 1983 1\n",
      "More in s2 0 50 13\n",
      "More in s1 743 792 4\n",
      "More in s2 0 48 4\n",
      "More in s2 0 55 1\n",
      "More in s1 402 447 8\n",
      "More in s1 55 102 7\n",
      "More in s2 0 61 6\n",
      "More in s1 251 294 15\n",
      "More in s1 204 252 2\n",
      "More in s1 257 307 11\n",
      "More in s1 263 307 6\n",
      "More in s1 251 294 15\n",
      "More in s2 0 44 6\n",
      "More in s2 0 50 14\n",
      "More in s1 1058 1101 6\n",
      "More in s2 0 52 1\n",
      "More in s2 0 47 10\n",
      "More in s1 70 112 11\n",
      "More in s1 109 156 18\n",
      "More in s1 154 196 3\n",
      "More in s2 0 42 4\n",
      "More in s1 109 156 18\n",
      "More in s1 153 196 5\n",
      "More in s1 152 200 1\n",
      "More in s2 0 44 7\n",
      "More in s2 0 43 9\n",
      "More in s2 0 44 10\n",
      "More in s2 0 43 7\n",
      "More in s1 156 200 3\n",
      "More in s1 491 537 3\n",
      "More in s2 0 47 9\n",
      "More in s2 0 43 7\n",
      "More in s2 0 46 7\n",
      "More in s1 373 420 2\n",
      "More in s1 256 304 2\n",
      "More in s1 492 537 4\n",
      "More in s1 -5 43 7\n",
      "More in s2 0 52 1\n",
      "More in s2 0 45 17\n",
      "More in s2 0 43 5\n",
      "More in s2 0 58 2\n",
      "More in s1 487 528 15\n",
      "More in s2 0 41 1\n",
      "More in s2 0 49 10\n",
      "More in s2 0 48 2\n",
      "More in s2 0 41 6\n",
      "More in s2 0 47 2\n",
      "More in s2 0 51 23\n",
      "More in s1 20 65 10\n",
      "More in s1 -6 40 11\n",
      "More in s2 0 52 1\n",
      "More in s1 8 54 0\n",
      "More in s1 13 54 3\n",
      "More in s1 -8 38 11\n",
      "More in s2 0 45 6\n",
      "More in s2 0 41 15\n",
      "More in s1 40 87 4\n",
      "More in s1 25 69 5\n",
      "More in s1 5 54 0\n",
      "More in s1 153 211 2\n",
      "More in s2 0 43 6\n",
      "More in s2 0 59 1\n",
      "More in s1 19 65 2\n",
      "More in s2 0 41 3\n",
      "More in s1 10 54 0\n",
      "More in s1 21 69 3\n",
      "More in s2 0 43 2\n",
      "More in s1 -2 40 7\n",
      "More in s2 0 43 3\n",
      "More in s2 0 54 2\n",
      "More in s2 0 49 7\n",
      "More in s2 0 43 3\n",
      "More in s2 0 65 4\n",
      "More in s1 -14 30 15\n",
      "More in s1 -7 38 13\n",
      "More in s2 0 43 3\n",
      "More in s1 402 447 8\n",
      "More in s2 0 43 1\n",
      "More in s2 0 45 21\n",
      "More in s2 0 47 14\n",
      "More in s2 0 50 1\n",
      "More in s2 0 59 6\n",
      "More in s2 0 51 8\n",
      "More in s2 0 44 1\n",
      "More in s1 346 390 16\n",
      "More in s2 0 46 8\n",
      "More in s1 586 630 17\n",
      "More in s2 0 50 11\n",
      "More in s2 0 41 1\n",
      "More in s1 1236 1278 10\n",
      "More in s2 0 47 5\n",
      "More in s1 235 279 17\n",
      "More in s2 0 43 18\n",
      "More in s2 0 44 17\n",
      "More in s2 0 41 8\n",
      "More in s2 0 49 1\n",
      "More in s2 0 51 18\n",
      "More in s2 0 46 1\n",
      "More in s2 0 50 3\n",
      "More in s2 0 50 10\n",
      "More in s2 0 44 6\n",
      "More in s1 241 282 14\n",
      "More in s2 0 47 4\n",
      "More in s2 0 43 11\n",
      "More in s1 504 547 1\n",
      "More in s1 -9 33 18\n",
      "More in s1 273 323 12\n",
      "More in s2 0 43 6\n",
      "More in s2 0 43 18\n",
      "More in s2 0 42 1\n",
      "More in s2 0 48 19\n",
      "More in s2 0 45 4\n",
      "More in s1 239 282 2\n",
      "More in s2 0 42 3\n",
      "More in s1 504 547 10\n",
      "More in s2 0 50 5\n",
      "More in s1 19 65 5\n",
      "More in s2 0 41 3\n",
      "More in s2 0 65 3\n",
      "More in s1 262 355 0\n",
      "More in s2 0 82 2\n",
      "More in s2 0 106 5\n",
      "More in s1 468 519 2\n",
      "More in s1 449 609 9\n",
      "More in s1 601 751 4\n",
      "More in s2 0 59 4\n",
      "More in s1 375 451 5\n",
      "More in s2 0 41 4\n",
      "More in s1 239 282 15\n",
      "More in s2 0 43 9\n",
      "More in s1 165 211 11\n",
      "More in s1 824 871 0\n",
      "More in s2 0 47 7\n",
      "More in s1 117 163 17\n",
      "More in s2 0 47 2\n",
      "More in s2 0 47 1\n",
      "More in s2 0 43 8\n",
      "More in s1 114 155 8\n",
      "More in s1 359 401 4\n",
      "More in s2 0 44 1\n",
      "More in s2 0 45 3\n",
      "More in s2 0 46 5\n",
      "More in s2 0 48 2\n",
      "More in s2 0 47 18\n",
      "More in s2 0 48 1\n",
      "More in s1 42 86 4\n",
      "More in s2 0 43 3\n",
      "More in s2 0 43 1\n",
      "More in s2 0 47 4\n",
      "More in s2 0 46 15\n",
      "More in s1 199 244 0\n",
      "More in s1 396 438 14\n",
      "More in s1 168 214 3\n",
      "More in s1 109 152 1\n",
      "More in s1 116 157 9\n",
      "More in s2 0 47 1\n",
      "More in s2 0 42 1\n",
      "More in s2 0 45 9\n",
      "More in s1 280 323 3\n",
      "More in s1 1172 1216 3\n",
      "More in s2 0 48 13\n",
      "More in s1 24 73 5\n",
      "More in s1 487 528 15\n",
      "More in s1 86 134 2\n",
      "More in s1 392 448 0\n",
      "More in s2 0 42 9\n",
      "More in s1 142 196 16\n",
      "More in s1 -4 43 18\n",
      "More in s1 824 871 0\n",
      "More in s2 0 44 21\n",
      "More in s1 86 131 4\n",
      "More in s1 108 155 7\n",
      "More in s2 0 50 1\n",
      "More in s1 1654 1700 12\n",
      "More in s1 459 505 0\n",
      "More in s1 245 288 17\n",
      "More in s2 0 44 3\n",
      "More in s2 0 50 5\n",
      "More in s2 0 43 1\n",
      "More in s2 0 41 4\n",
      "More in s2 0 41 9\n",
      "More in s1 65 109 22\n",
      "More in s1 251 296 10\n",
      "More in s1 21 69 3\n",
      "More in s2 0 49 1\n",
      "More in s1 108 152 1\n",
      "More in s2 0 48 3\n",
      "More in s2 0 50 14\n",
      "More in s2 0 47 3\n",
      "More in s1 386 435 0\n",
      "More in s1 55 102 7\n",
      "More in s1 1508 1550 1\n",
      "More in s1 1658 1700 16\n",
      "More in s2 0 46 17\n",
      "More in s2 0 42 10\n",
      "More in s2 0 48 1\n",
      "More in s2 0 43 2\n",
      "More in s1 109 155 12\n",
      "More in s1 1939 1983 0\n",
      "More in s2 0 45 5\n",
      "More in s1 1940 1983 8\n",
      "More in s2 0 44 8\n",
      "More in s2 0 42 17\n",
      "More in s2 0 44 6\n",
      "More in s1 697 741 6\n",
      "More in s2 0 46 3\n",
      "More in s2 0 53 8\n",
      "More in s2 0 49 11\n",
      "More in s2 0 45 8\n",
      "More in s1 45 91 16\n",
      "More in s1 63 110 5\n",
      "More in s2 0 50 7\n",
      "More in s2 0 43 16\n",
      "More in s1 323 369 19\n",
      "More in s1 466 517 1\n",
      "More in s1 205 252 2\n",
      "More in s1 -2 40 7\n",
      "More in s2 0 44 4\n",
      "More in s1 470 517 4\n",
      "More in s1 249 303 2\n",
      "More in s2 0 47 18\n",
      "More in s2 0 46 1\n",
      "More in s1 271 323 2\n",
      "More in s1 275 323 5\n",
      "More in s1 250 294 22\n",
      "More in s1 108 150 1\n",
      "More in s1 0 42 7\n",
      "More in s2 0 54 2\n",
      "More in s2 0 44 1\n",
      "More in s2 0 47 3\n",
      "More in s1 278 321 13\n",
      "More in s1 464 505 0\n",
      "More in s1 274 319 0\n",
      "More in s2 0 45 6\n",
      "More in s1 594 638 9\n",
      "More in s1 27 69 7\n",
      "More in s2 0 43 9\n",
      "More in s1 1058 1101 6\n",
      "More in s1 26 75 5\n",
      "More in s2 0 44 11\n",
      "More in s2 0 47 4\n",
      "More in s1 73 124 1\n",
      "More in s2 0 45 21\n",
      "More in s2 0 51 1\n",
      "More in s2 0 45 1\n",
      "More in s1 109 155 12\n",
      "More in s1 118 163 16\n",
      "More in s2 0 49 22\n",
      "More in s2 0 52 1\n",
      "More in s2 0 49 7\n",
      "More in s2 0 45 16\n",
      "More in s2 0 42 2\n",
      "More in s2 0 42 2\n",
      "More in s2 0 45 13\n",
      "More in s1 254 303 2\n",
      "More in s1 245 296 1\n",
      "More in s2 0 44 14\n",
      "More in s1 112 165 2\n",
      "More in s1 257 303 1\n",
      "More in s1 262 303 2\n",
      "More in s1 250 303 1\n",
      "More in s1 49 91 17\n",
      "More in s2 0 48 1\n",
      "More in s2 0 48 3\n",
      "More in s2 0 46 3\n",
      "More in s1 213 257 5\n",
      "More in s2 0 47 4\n",
      "More in s2 0 49 15\n",
      "More in s2 0 44 3\n",
      "More in s2 0 43 3\n",
      "More in s2 0 49 3\n",
      "More in s2 0 43 4\n",
      "More in s2 0 45 20\n",
      "More in s2 0 47 10\n",
      "More in s1 110 159 15\n",
      "More in s2 0 42 8\n",
      "More in s2 0 46 9\n",
      "More in s1 187 237 0\n",
      "More in s2 0 44 4\n",
      "More in s2 0 43 6\n",
      "More in s2 0 43 9\n",
      "More in s1 15 59 2\n",
      "More in s2 0 46 17\n",
      "More in s1 276 323 4\n",
      "More in s1 91 158 5\n",
      "More in s2 0 48 4\n",
      "More in s2 0 48 2\n",
      "More in s1 252 321 18\n",
      "More in s2 0 44 12\n",
      "More in s2 0 43 1\n",
      "More in s2 0 50 4\n",
      "More in s1 246 292 0\n",
      "More in s1 248 292 0\n",
      "More in s2 0 63 1\n",
      "More in s2 0 47 8\n",
      "More in s1 265 321 19\n",
      "More in s2 0 43 7\n",
      "More in s2 0 47 2\n",
      "More in s2 0 49 19\n",
      "More in s2 0 58 1\n",
      "More in s2 0 41 1\n",
      "More in s2 0 43 6\n",
      "More in s1 94 158 2\n",
      "More in s2 0 43 14\n",
      "More in s2 0 50 1\n",
      "More in s2 0 44 16\n",
      "More in s1 62 107 3\n",
      "More in s1 8 49 3\n",
      "More in s2 0 47 1\n",
      "More in s2 0 51 23\n",
      "More in s2 0 48 1\n",
      "More in s1 257 307 11\n",
      "More in s2 0 45 4\n",
      "More in s2 0 47 3\n",
      "More in s1 118 163 16\n",
      "More in s2 0 43 1\n",
      "More in s2 0 42 12\n",
      "More in s1 392 435 0\n",
      "More in s2 0 50 15\n",
      "More in s2 0 57 23\n",
      "More in s2 0 51 13\n",
      "More in s2 0 51 3\n",
      "More in s1 17 60 7\n",
      "More in s2 0 44 4\n",
      "More in s1 -8 40 13\n",
      "More in s1 434 476 10\n",
      "More in s2 0 45 6\n",
      "More in s1 33 75 15\n",
      "More in s2 0 46 3\n",
      "More in s1 431 476 8\n",
      "More in s2 0 46 3\n",
      "More in s1 912 953 13\n",
      "More in s1 -13 36 20\n",
      "More in s2 0 41 1\n",
      "More in s2 0 57 1\n",
      "More in s2 0 43 1\n",
      "More in s2 0 45 21\n",
      "More in s2 0 41 15\n",
      "More in s1 164 211 7\n",
      "More in s1 166 211 22\n",
      "More in s1 1107 1149 8\n",
      "More in s2 0 51 13\n",
      "More in s2 0 57 23\n",
      "More in s2 0 51 3\n",
      "More in s1 58 109 0\n",
      "More in s2 0 43 1\n",
      "More in s2 0 42 5\n",
      "More in s1 1356 1399 2\n",
      "More in s2 0 45 13\n",
      "More in s1 106 155 2\n",
      "More in s1 238 292 12\n",
      "More in s2 0 52 6\n",
      "More in s2 0 53 11\n",
      "More in s1 350 396 13\n",
      "More in s2 0 49 2\n",
      "More in s2 0 42 2\n",
      "More in s1 137 182 12\n",
      "More in s2 0 45 15\n",
      "More in s2 0 47 14\n",
      "More in s2 0 45 5\n",
      "More in s2 0 45 21\n",
      "More in s2 0 47 5\n",
      "More in s1 165 211 11\n",
      "More in s1 236 282 9\n",
      "More in s2 0 42 9\n",
      "More in s1 386 435 0\n",
      "More in s2 0 48 1\n",
      "More in s2 0 41 11\n",
      "More in s1 594 638 9\n",
      "More in s2 0 42 2\n",
      "More in s2 0 46 15\n",
      "More in s2 0 56 1\n",
      "More in s2 0 47 4\n",
      "More in s2 0 50 1\n",
      "More in s1 849 892 20\n",
      "More in s2 0 42 6\n",
      "More in s2 0 57 2\n",
      "More in s2 0 50 2\n",
      "More in s2 0 44 12\n",
      "More in s2 0 42 8\n",
      "More in s2 0 45 14\n",
      "More in s2 0 44 6\n",
      "More in s2 0 51 11\n",
      "More in s2 0 50 1\n",
      "More in s2 0 42 8\n",
      "More in s2 0 49 12\n",
      "More in s2 0 47 19\n",
      "More in s1 85 129 17\n",
      "More in s2 0 43 15\n",
      "More in s1 1937 1983 11\n",
      "More in s1 297 342 21\n",
      "More in s2 0 44 12\n",
      "More in s2 0 44 1\n",
      "More in s2 0 49 20\n",
      "More in s2 0 45 15\n",
      "More in s2 0 43 6\n",
      "More in s1 23 69 8\n",
      "More in s1 8 49 3\n",
      "More in s2 0 45 14\n",
      "More in s1 26 69 1\n",
      "More in s1 7 49 17\n",
      "More in s2 0 53 3\n",
      "More in s2 0 48 17\n",
      "More in s1 54 100 8\n",
      "More in s2 0 42 1\n",
      "More in s1 110 155 2\n",
      "More in s1 22 69 2\n",
      "More in s1 26 69 9\n",
      "More in s2 0 55 13\n",
      "More in s2 0 58 2\n",
      "More in s1 97 138 13\n",
      "More in s1 86 131 4\n",
      "More in s1 174 221 21\n",
      "More in s1 251 294 21\n",
      "More in s2 0 50 4\n",
      "More in s1 26 69 7\n",
      "More in s2 0 48 1\n",
      "More in s2 0 49 1\n",
      "More in s1 26 73 0\n",
      "More in s2 0 42 18\n",
      "More in s1 24 66 1\n",
      "More in s1 263 307 6\n",
      "More in s2 0 52 1\n",
      "More in s2 0 50 1\n",
      "More in s2 0 51 6\n",
      "More in s2 0 45 3\n",
      "More in s2 0 46 1\n",
      "More in s2 0 45 3\n",
      "More in s1 54 100 8\n",
      "More in s2 0 42 8\n",
      "More in s1 7 59 2\n",
      "More in s1 16 73 1\n",
      "More in s1 -3 56 6\n",
      "More in s1 -5 52 5\n",
      "More in s1 128 184 5\n",
      "More in s2 0 48 2\n",
      "More in s2 0 42 4\n",
      "More in s2 0 44 1\n",
      "More in s2 0 44 8\n",
      "More in s2 0 46 1\n",
      "More in s2 0 45 21\n",
      "More in s2 0 46 18\n",
      "More in s1 81 126 5\n",
      "More in s2 0 44 16\n",
      "More in s2 0 42 7\n",
      "More in s2 0 46 17\n",
      "More in s1 243 288 12\n",
      "More in s2 0 46 1\n",
      "More in s2 0 42 17\n",
      "More in s2 0 42 2\n",
      "More in s2 0 48 4\n",
      "More in s2 0 49 1\n",
      "More in s1 242 295 5\n",
      "More in s2 0 47 3\n",
      "More in s1 66 126 1\n",
      "More in s1 600 643 1\n",
      "Total nodes: 269088\n",
      "Total errors: 658\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "create_segmented_nodes(nodes_fname, segment_map, seg_nodes_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes - find transcript words corresponding to node start and end times\n",
    "\n",
    "Create node dictionary:\n",
    "    - node id\n",
    "    - file id\n",
    "    - seg id\n",
    "    - start time\n",
    "    - end time\n",
    "    - es words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_align_words_for_node(align_words_list, start, end):\n",
    "    #display(align_words_list, start, end)\n",
    "    words, start_times, end_times = zip(*(align_words_list))\n",
    "    start_i = bisect.bisect(end_times, start)\n",
    "    # end index will be 1 beyond the actual end\n",
    "    end_i = bisect.bisect(start_times, end)\n",
    "    return words[start_i:end_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VAMOS', 'A', 'VER')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('ESTA', 'MECHITA')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(find_align_words_for_node(align_dict[\"001\"][\"001.224\"][\"es\"], 191, 246))\n",
    "display(find_align_words_for_node(align_dict[\"001\"][\"001.274\"][\"es\"], 45, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_nodes_align(seg_nodes_fname, segment_map, align_dict):\n",
    "    total_errors = 0\n",
    "    nodes_dict = {}\n",
    "    with open(seg_nodes_fname, \"r\") as seg_nodes_f:\n",
    "        for nid, line in enumerate(seg_nodes_f, start=1):\n",
    "            line_items = line.strip().split()\n",
    "            file_id = line_items[0].split('.')[0]\n",
    "            seg_id = line_items[0]\n",
    "            start_t, end_t = map(int, line_items[1:3])\n",
    "            if seg_id in align_dict[file_id]:\n",
    "                es_w = find_align_words_for_node(align_dict[file_id][seg_id]['es'], start_t, end_t)\n",
    "                if len(align_dict[file_id][seg_id]['es_cnt']) > 0:\n",
    "                    es_cnt_w = find_align_words_for_node(align_dict[file_id][seg_id]['es_cnt'], start_t, end_t)\n",
    "                else:\n",
    "                    es_cnt_w = tuple()\n",
    "                    total_errors += 1\n",
    "            else:\n",
    "                es_w = tuple()\n",
    "                total_errors += 1\n",
    "            \n",
    "            nodes_dict[nid] = Node(file_id, seg_id, start_t, end_t, es_w, es_cnt_w)\n",
    "            if nid % 100000 == 0:\n",
    "                print('reading node %d' % nid)\n",
    "    print(\"finished reading %d nodes\" % nid)\n",
    "    print('No content words found for %d nodes' % total_errors)\n",
    "    return nodes_dict\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading node 100000\n",
      "reading node 200000\n",
      "finished reading 269088 nodes\n",
      "No content words found for 688 nodes\n"
     ]
    }
   ],
   "source": [
    "nodes_dict = map_nodes_align(seg_nodes_fname, segment_map, align_dict)\n",
    "pickle.dump(nodes_dict, open(nodes_dict_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges - create a valid edges file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_edges():\n",
    "    olap_dict = {}\n",
    "    pairs_list = []\n",
    "    # process clusters file\n",
    "    with open(config['es']['edges_olap_fname'], \"r\") as in_f:\n",
    "        for i, line in enumerate(in_f):\n",
    "            line_items = map(int, line.strip().split())\n",
    "            olap_dict[line_items[0]] = line_items[0]\n",
    "            if len(line_items) > 1:\n",
    "                for j in line_items[1:]:\n",
    "                    olap_dict[j] = line_items[0]\n",
    "\n",
    "    # Read edges dict\n",
    "    with open(config['es']['edges_utd_fname'], \"r\") as in_f:\n",
    "        for i, line in enumerate(in_f):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Processing line: %d\" % (i+1))\n",
    "            line_items = line.strip().split()\n",
    "            node_1 = int(line_items[0])\n",
    "            node_2 = int(line_items[1])\n",
    "            if node_1 not in olap_dict:\n",
    "                olap_dict[node_1] = node_1\n",
    "            if node_2 not in olap_dict:\n",
    "                olap_dict[node_2] = node_2\n",
    "            dtw_val = float(line_items[2]) / 1000.0\n",
    "\n",
    "            node_1 = olap_dict[node_1]\n",
    "            node_2 = olap_dict[node_2]\n",
    "\n",
    "            # Add to pairs list as a tuple\n",
    "            pairs_list.append((min(node_1, node_2), max(node_1, node_2), dtw_val))\n",
    "\n",
    "\n",
    "    print(\"Finished - reading edges ...\")\n",
    "    print(\"Removing duplicates in pairs list\")\n",
    "    set_pairs = list(set(pairs_list))\n",
    "    print(\"Set length: %d and List length: %d\" %(len(set_pairs), len(pairs_list)))\n",
    "    pairs_list = sorted(list(set_pairs))\n",
    "    with open(config['es']['edges_score_fname'], \"w\") as out_f:\n",
    "        for (n1, n2, dtw) in set_pairs:\n",
    "            out_line = \"%d\\t%d\\t%.3f\\n\" % (n1, n2, dtw)\n",
    "            out_f.write(out_line)\n",
    "    pickle.dump(set_pairs, open(config['es']['score_pairs_fname'], \"wb\"))\n",
    "    print(\"finished writing edges\")\n",
    "    \n",
    "    # validity check for duplicates\n",
    "    set_nodes_only = [(n1,n2) for n1, n2, dtw in set_pairs]\n",
    "    if len(set_pairs) != len(set_nodes_only):\n",
    "        raise IOError\n",
    "    return pairs_list   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing line: 1\n",
      "Processing line: 1001\n",
      "Processing line: 2001\n",
      "Processing line: 3001\n",
      "Processing line: 4001\n",
      "Processing line: 5001\n",
      "Processing line: 6001\n",
      "Processing line: 7001\n",
      "Processing line: 8001\n",
      "Processing line: 9001\n",
      "Processing line: 10001\n",
      "Processing line: 11001\n",
      "Processing line: 12001\n",
      "Processing line: 13001\n",
      "Processing line: 14001\n",
      "Processing line: 15001\n",
      "Processing line: 16001\n",
      "Processing line: 17001\n",
      "Processing line: 18001\n",
      "Processing line: 19001\n",
      "Processing line: 20001\n",
      "Processing line: 21001\n",
      "Processing line: 22001\n",
      "Processing line: 23001\n",
      "Processing line: 24001\n",
      "Processing line: 25001\n",
      "Processing line: 26001\n",
      "Processing line: 27001\n",
      "Processing line: 28001\n",
      "Processing line: 29001\n",
      "Processing line: 30001\n",
      "Processing line: 31001\n",
      "Processing line: 32001\n",
      "Processing line: 33001\n",
      "Processing line: 34001\n",
      "Processing line: 35001\n",
      "Processing line: 36001\n",
      "Processing line: 37001\n",
      "Processing line: 38001\n",
      "Processing line: 39001\n",
      "Processing line: 40001\n",
      "Processing line: 41001\n",
      "Processing line: 42001\n",
      "Processing line: 43001\n",
      "Processing line: 44001\n",
      "Processing line: 45001\n",
      "Processing line: 46001\n",
      "Processing line: 47001\n",
      "Processing line: 48001\n",
      "Processing line: 49001\n",
      "Processing line: 50001\n",
      "Processing line: 51001\n",
      "Processing line: 52001\n",
      "Processing line: 53001\n",
      "Processing line: 54001\n",
      "Processing line: 55001\n",
      "Processing line: 56001\n",
      "Processing line: 57001\n",
      "Processing line: 58001\n",
      "Processing line: 59001\n",
      "Processing line: 60001\n",
      "Processing line: 61001\n",
      "Processing line: 62001\n",
      "Processing line: 63001\n",
      "Processing line: 64001\n",
      "Processing line: 65001\n",
      "Processing line: 66001\n",
      "Processing line: 67001\n",
      "Processing line: 68001\n",
      "Processing line: 69001\n",
      "Processing line: 70001\n",
      "Processing line: 71001\n",
      "Processing line: 72001\n",
      "Processing line: 73001\n",
      "Processing line: 74001\n",
      "Processing line: 75001\n",
      "Processing line: 76001\n",
      "Processing line: 77001\n",
      "Processing line: 78001\n",
      "Processing line: 79001\n",
      "Processing line: 80001\n",
      "Processing line: 81001\n",
      "Processing line: 82001\n",
      "Processing line: 83001\n",
      "Processing line: 84001\n",
      "Processing line: 85001\n",
      "Processing line: 86001\n",
      "Processing line: 87001\n",
      "Processing line: 88001\n",
      "Processing line: 89001\n",
      "Processing line: 90001\n",
      "Processing line: 91001\n",
      "Processing line: 92001\n",
      "Processing line: 93001\n",
      "Processing line: 94001\n",
      "Processing line: 95001\n",
      "Processing line: 96001\n",
      "Processing line: 97001\n",
      "Processing line: 98001\n",
      "Processing line: 99001\n",
      "Processing line: 100001\n",
      "Processing line: 101001\n",
      "Processing line: 102001\n",
      "Processing line: 103001\n",
      "Processing line: 104001\n",
      "Processing line: 105001\n",
      "Processing line: 106001\n",
      "Processing line: 107001\n",
      "Processing line: 108001\n",
      "Processing line: 109001\n",
      "Processing line: 110001\n",
      "Processing line: 111001\n",
      "Processing line: 112001\n",
      "Processing line: 113001\n",
      "Processing line: 114001\n",
      "Processing line: 115001\n",
      "Processing line: 116001\n",
      "Processing line: 117001\n",
      "Processing line: 118001\n",
      "Processing line: 119001\n",
      "Processing line: 120001\n",
      "Processing line: 121001\n",
      "Processing line: 122001\n",
      "Processing line: 123001\n",
      "Processing line: 124001\n",
      "Processing line: 125001\n",
      "Processing line: 126001\n",
      "Processing line: 127001\n",
      "Processing line: 128001\n",
      "Processing line: 129001\n",
      "Processing line: 130001\n",
      "Processing line: 131001\n",
      "Processing line: 132001\n",
      "Processing line: 133001\n",
      "Processing line: 134001\n",
      "Finished - reading edges ...\n",
      "Removing duplicates in pairs list\n",
      "Set length: 123247 and List length: 134544\n",
      "finished writing edges\n"
     ]
    }
   ],
   "source": [
    "valid_pairs = read_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clusters\n",
    "\n",
    "- Save list of clusters\n",
    "- Generate bag of cluster ids for each segment\n",
    "    - use nodes per segment as replace with cluster id\n",
    "    - if no node found, use cluster id -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17394\n"
     ]
    }
   ],
   "source": [
    "segids = []\n",
    "for fid in segment_map:\n",
    "    segids.extend(segment_map[fid].keys())\n",
    "print(len(segids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_clusters(clusters_utd_fname):\n",
    "    clusters = []\n",
    "    with open(clusters_utd_fname, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            try:\n",
    "                nodes = map(int, line.strip().split())\n",
    "                clusters.append(nodes)\n",
    "            except:\n",
    "                print(line)                    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = load_clusters(clusters_utd_fname)\n",
    "pickle.dump(clusters, open(clusters_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pseudowords_for_segments(segment_map, nodes_dict, clusters, feats_fname, feats_dict_fname):\n",
    "    feats_dict = {}\n",
    "    total_errors = 0\n",
    "    display_den = len(clusters) // 10\n",
    "    \n",
    "    for clid, nodes in enumerate(clusters, start=1):\n",
    "        if clid % display_den == 0:\n",
    "            print('processing cluster %d out of %d' % (clid, len(clusters)))\n",
    "        for nid in nodes:\n",
    "            node = nodes_dict[nid]\n",
    "            if node.seg not in feats_dict:\n",
    "                feats_dict[node.seg] = []\n",
    "            feats_dict[node.seg].append(str(clid))\n",
    "    \n",
    "    print(\"total clusters: %d\" % clid)\n",
    "    # Get complete list of segment ids\n",
    "    segids = []\n",
    "    for fid in segment_map:\n",
    "        segids.extend(segment_map[fid].keys())\n",
    "    \n",
    "    with open(feats_fname, \"w\") as out_f:\n",
    "        for seg_id in sorted(segids):\n",
    "            # adding -1 for missing pseudotext\n",
    "            if seg_id not in feats_dict:\n",
    "                #outline = \"-1\\n\"\n",
    "                total_errors += 1\n",
    "                feats_dict[seg_id] = ['-1']\n",
    "            \n",
    "            outline = \" \".join(map(str,sorted(feats_dict[seg_id])))\n",
    "            outline = outline.strip() + \"\\n\"\n",
    "            out_f.write(outline)\n",
    "            \n",
    "    print(\"Finished writing features file: %s\" % os.path.basename(feats_fname))\n",
    "    print(\"Writing to file: %s\" % os.path.basename(feats_dict_fname))\n",
    "    pickle.dump(feats_dict, open(feats_dict_fname, \"wb\"))\n",
    "    print(\"Psuedowords not found for: %d segments, out of total: %d segments\" % (total_errors, len(segids)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing cluster 3984 out of 39843\n",
      "processing cluster 7968 out of 39843\n",
      "processing cluster 11952 out of 39843\n",
      "processing cluster 15936 out of 39843\n",
      "processing cluster 19920 out of 39843\n",
      "processing cluster 23904 out of 39843\n",
      "processing cluster 27888 out of 39843\n",
      "processing cluster 31872 out of 39843\n",
      "processing cluster 35856 out of 39843\n",
      "processing cluster 39840 out of 39843\n",
      "total clusters: 39843\n",
      "Finished writing features file: pseudowords.feats\n",
      "Writing to file: pseudowords.dict\n",
      "Psuedowords not found for: 5371 segments, out of total: 17394 segments\n"
     ]
    }
   ],
   "source": [
    "generate_pseudowords_for_segments(segment_map, nodes_dict, clusters, feats_fname, feats_dict_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
