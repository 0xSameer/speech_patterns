{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_and_create_dirs():\n",
    "    folders_to_check = [config[\"es\"][\"exp_path\"], config[\"es\"][\"out_path\"]]\n",
    "    for folder in folders_to_check:\n",
    "        if not os.path.exists(folder):\n",
    "            print(\"creating folder: {0:s}\".format(folder))\n",
    "            os.makedirs(folder)\n",
    "    print(\"...\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wav_file_list(prefix, wav_path):\n",
    "    wav_file_list = [os.path.join(prefix, wav_file) for \\\n",
    "                     wav_file in os.listdir(wav_path) if wav_file.endswith(\".wav\")]\n",
    "    wav_file_list_string = \"\\n\".join(wav_file_list)\n",
    "    return wav_file_list_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_file_lst(file_lst_fname):\n",
    "    with open(file_lst_fname, \"w\") as out_f:\n",
    "        for folder in [\"train\", \"test\"]:\n",
    "            wav_file_list_string = get_wav_file_list(config[\"es\"][folder][\"lst_file_prefix\"], \n",
    "                                                     config['es'][folder]['wavs'])\n",
    "            out_f.write(wav_file_list_string)\n",
    "        \n",
    "    print(\"Finished writing files.lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_plp(wav_fname, plp_fname):\n",
    "    FEACALC = config['base'][\"feacalc\"]\n",
    "    subprocess.call([FEACALC,\"-plp\", \\\n",
    "                    \"12\", \"-cep\", \"13\", \"-dom\", \"cep\", \"-deltaorder\", \\\n",
    "                    \"2\", \"-dither\", \"-frqaxis\", \"bark\", \"-samplerate\", \\\n",
    "                    \"8000\", \"-win\", \"25\", \"-step\", \"10\", \"-ip\", \\\n",
    "                    \"MSWAVE\", \"-rasta\", \"false\", \"-compress\", \\\n",
    "                    \"true\", \"-op\", \"swappedraw\", \"-o\", plp_fname, wav_fname])\n",
    "\n",
    "    \n",
    "def normalize_plp(plp_fname, vad_fname, plp_norm_fname):\n",
    "    STANDFEAT = config['base'][\"standfeat\"]\n",
    "    # Standardize binary file, for VAD regions only\n",
    "    subprocess.call([STANDFEAT, \"-D\", \"39\", \"-infile\", \\\n",
    "                    plp_fname, \"-outfile\", plp_norm_fname, \\\n",
    "                    \"-vadfile\", vad_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_and_normalize_plps():\n",
    "    for i, file_id in enumerate(segment_map):\n",
    "        wav_fname = os.path.join(merged_wavs_path, file_id+\".wav\")\n",
    "        vad_fname = os.path.join(merged_fa_vads_path, file_id+\".vad\")\n",
    "        plp_fname = os.path.join(plp_path, file_id+\".binary\")\n",
    "        plp_norm_fname = os.path.join(plp_norm_path, file_id+\".std.binary\")\n",
    "\n",
    "        #print(file_id, wav_fname, vad_fname, plp_fname, plp_norm_fname)\n",
    "\n",
    "        # create PLP\n",
    "        if i % 20 == 0:\n",
    "            print(\"plp for file %s \" % file_id)\n",
    "\n",
    "        #if not os.path.exists(plp_fname):\n",
    "        create_plp(wav_fname, plp_fname)\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(\"normalizing plp %s\" % file_id)\n",
    "\n",
    "        #if not os.path.exists(plp_norm_fname):\n",
    "        normalize_plp(plp_fname, vad_fname, plp_norm_fname)\n",
    "    print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSH files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lsh_proj_file(lsh_proj_fname):\n",
    "    subprocess.call([config['base'][\"lsh_genproj\"], \\\n",
    "                     \"-D\",\"39\",\"-S\",\"64\",\"-seed\", \\\n",
    "                     \"1\",\"-projfile\", lsh_proj_fname])\n",
    "\n",
    "def create_lsh_file(plp_norm_fname, vad_fname, lsh_proj_fname, lsh_fname):\n",
    "    LSH = config['base'][\"lsh\"]\n",
    "    subprocess.call([LSH, \"-D\", \"39\", \"-S\", \"64\", \\\n",
    "                    \"-projfile\", lsh_proj_fname, \\\n",
    "                    \"-featfile\", plp_norm_fname, \"-sigfile\", \\\n",
    "                    lsh_fname, \"-vadfile\", vad_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def create_lsh_files():\n",
    "#     # create lsh projection seed file\n",
    "#     file_list = []\n",
    "#     lsh_proj_fname = os.path.join(config[\"es\"][\"data_path\"], \"proj_S64xD39_seed1\")\n",
    "#     create_lsh_proj_file(lsh_proj_fname)\n",
    "    \n",
    "#     # create lsh files for both train and test sets    \n",
    "#     for folder in [\"train\", \"test\"]:\n",
    "#         if not os.path.exists(config['es']['lsh_path']):\n",
    "#             os.makedirs(config['es']['lsh_path'])\n",
    "#         if not os.path.exists(config['es']['plp_binary']):\n",
    "#             os.makedirs(config['es']['plp_binary'])\n",
    "        \n",
    "#         sys.stderr.flush()\n",
    "        \n",
    "#         if folder == \"train\":\n",
    "#             plp_key = \"plp_npy\"\n",
    "#             plp_extn = \".plp.npy\"\n",
    "#         else:\n",
    "#             plp_key = \"plp_binary\"\n",
    "#             plp_extn = \".bin\"\n",
    "        \n",
    "#         plp_files = [f for f in os.listdir(config['es'][folder][plp_key]) if f.endswith(plp_extn)]\n",
    "#         with tqdm(total=len(plp_files)) as pbar:\n",
    "#             for i, plp_file in enumerate(plp_files, start=1):\n",
    "#                 plp_file_base = plp_file.replace(plp_extn, \"\")\n",
    "#                 plp_fname = (os.path.join(config['es'][folder][plp_key], plp_file))\n",
    "#                 plp_binary_fname = (os.path.join(config['es']['plp_binary'], \n",
    "#                                           \"{0:s}.binary\".format(plp_file_base)))\n",
    "#                 plp_norm_fname = (os.path.join(config['es']['plp_binary'], \n",
    "#                                           \"{0:s}.std.binary\".format(plp_file_base)))\n",
    "#                 vad_fname = (os.path.join(config['es'][folder]['vad_path'], \n",
    "#                                           \"{0:s}.vad\".format(plp_file_base)))\n",
    "#                 lsh_fname = (os.path.join(config['es']['lsh_path'], \n",
    "#                                           \"{0:s}.std.lsh64\".format(plp_file_base)))\n",
    "#                 #print(plp_file, plp_fname, plp_binary_fname, vad_fname, lsh_fname)\n",
    "#                 if folder == \"train\":\n",
    "#                     x = np.load(plp_fname)\n",
    "#                     y = x.ravel()\n",
    "#                     y.tofile(plp_binary_fname)\n",
    "#                 else:\n",
    "#                     shutil.copyfile(plp_fname, plp_binary_fname)\n",
    "                \n",
    "#                 normalize_plp(plp_binary_fname, vad_fname, plp_norm_fname)\n",
    "                \n",
    "#                 # create lsh\n",
    "#                 create_lsh_file(plp_norm_fname, vad_fname, lsh_proj_fname, lsh_fname)\n",
    "#                 file_list.append(plp_file_base)\n",
    "\n",
    "#                 # update progress\n",
    "#                 pbar.set_description(\"processing {0:s}\".format(plp_file_base))\n",
    "#                 pbar.update(1)\n",
    "#     print(\"completed set {0:s}\".format(folder))\n",
    "#     return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lsh_files():\n",
    "    # create lsh projection seed file\n",
    "    file_list = []\n",
    "    lsh_proj_fname = os.path.join(config[\"es\"][\"data_path\"], \"proj_S64xD39_seed1\")\n",
    "    create_lsh_proj_file(lsh_proj_fname)\n",
    "    \n",
    "    # create lsh files for both train and test sets    \n",
    "    for folder in [\"train\", \"test\"]:\n",
    "        if not os.path.exists(config['es']['lsh_path']):\n",
    "            os.makedirs(config['es']['lsh_path'])\n",
    "        if not os.path.exists(config['es']['plp_binary']):\n",
    "            os.makedirs(config['es']['plp_binary'])\n",
    "        \n",
    "        sys.stderr.flush()\n",
    "        \n",
    "        wav_files = [f for f in os.listdir(config['es'][folder]['wavs']) if f.endswith(\".wav\")]\n",
    "        with tqdm(total=len(wav_files)) as pbar:\n",
    "            for i, wav_file in enumerate(wav_files, start=1):\n",
    "                wav_file_base = wav_file.replace(\".wav\", \"\")\n",
    "                wav_file_fname = os.path.join(config['es'][folder]['wavs'], wav_file)\n",
    "                plp_binary_fname = (os.path.join(config['es']['plp_binary'], \n",
    "                                          \"{0:s}.binary\".format(wav_file_base)))\n",
    "                plp_norm_fname = (os.path.join(config['es']['plp_binary'], \n",
    "                                          \"{0:s}.std.binary\".format(wav_file_base)))\n",
    "                vad_fname = (os.path.join(config['es'][folder]['vad_path'], \n",
    "                                          \"{0:s}.vad\".format(wav_file_base)))\n",
    "                lsh_fname = (os.path.join(config['es']['lsh_path'], \n",
    "                                          \"{0:s}.std.lsh64\".format(wav_file_base)))\n",
    "                \n",
    "                create_plp(wav_file_fname, plp_binary_fname)\n",
    "                normalize_plp(plp_binary_fname, vad_fname, plp_norm_fname)\n",
    "                \n",
    "                # create lsh\n",
    "                create_lsh_file(plp_norm_fname, vad_fname, lsh_proj_fname, lsh_fname)\n",
    "                file_list.append(wav_file_base)\n",
    "\n",
    "                # update progress\n",
    "                pbar.set_description(\"processing {0:s}\".format(wav_file_base))\n",
    "                pbar.update(1)\n",
    "    print(\"completed set {0:s}\".format(folder))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ZRTools discovery command files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file_list():\n",
    "    file_list = {\"train\":[], \"test\":[]}\n",
    "    # read training files\n",
    "    with open(config[\"es\"][\"filemap\"], \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            fname = line.strip()\n",
    "            if not os.path.exists(\"{0:s}.plp.npy\".format(os.path.join(config['es']['train']['plp_npy'], \n",
    "                                                                      fname))):\n",
    "                print(\"file = {0:s} not found\".format(fname))\n",
    "            else:\n",
    "                file_list[\"train\"].append(fname)\n",
    "    # read test files\n",
    "    plp_files = [f for f in os.listdir(config['es'][\"test\"][\"plp_binary\"]) if f.endswith(\".bin\")]\n",
    "    for i, plp_file in enumerate(plp_files, start=1):\n",
    "        plp_file_base = plp_file.replace(\".bin\", \"\")\n",
    "        file_list[\"test\"].append(plp_file_base)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_files_base(file_list):\n",
    "    file_list = read_file_list()\n",
    "    with open(config[\"es\"][\"lst_file_base\"], \"w\") as out_f:\n",
    "        for wav_file in (file_list[\"train\"] + file_list[\"test\"]):\n",
    "            out_f.write(wav_file+'\\n')\n",
    "    print(\"Generated files.base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_discovery_cmd_scripts(num_splits=1):\n",
    "    exp_path = config[\"es\"][\"exp_path\"]\n",
    "    file_list = read_file_list()\n",
    "    wav_file_list = file_list[\"train\"] + file_list[\"test\"]\n",
    "    exp_name = config[\"es\"][\"exp_name\"]\n",
    "    \n",
    "    disc_file_split_base = \"disc_{0:d}.cmd\"\n",
    "    disc_file_split = os.path.join(exp_path, disc_file_split_base)\n",
    "    disc_split_file = os.path.join(exp_path, \"disc_split.txt\")\n",
    "    num_files = len(wav_file_list)\n",
    "    exp_local_path = os.path.join(\"exp\", exp_name)\n",
    "    cmd_string = \"scripts/plebdisc_filepair \\\"{0:s}\\\" \\\"{1:s}\\\" {2:s} 39\\n\"\n",
    "\n",
    "    total_lines = num_files * num_files\n",
    "    lines_per_file = total_lines // num_splits\n",
    "    smallfile = None\n",
    "    curr_line = 0\n",
    "    curr_file_num = 0\n",
    "\n",
    "    for i in range(num_files) :\n",
    "        if i % 20 == 0:\n",
    "            print(\"Progress: {0:d} out of: {1:d}\".format(curr_line+1, total_lines))\n",
    "        for j in range(num_files):\n",
    "            out_line = cmd_string.format(wav_file_list[i], \\\n",
    "                                              wav_file_list[j], \\\n",
    "                                              exp_local_path)\n",
    "            if curr_line % lines_per_file == 0:\n",
    "                if smallfile:\n",
    "                    smallfile.close()\n",
    "                small_filename = disc_file_split.format(curr_file_num)\n",
    "                smallfile = open(small_filename, \"w\")\n",
    "                curr_file_num += 1\n",
    "            smallfile.write(out_line)\n",
    "            curr_line += 1\n",
    "    if smallfile:\n",
    "        smallfile.close()\n",
    "\n",
    "    # Making a list of commands to execute the split disc list\n",
    "    full_split_cmd_string = \"nice sh {0:s} 1> {1:s} 2>{2:s} &\\n\"\n",
    "    split_cmd = os.path.join(exp_local_path, \"matches\",\"{0:s}.{1:d}\")\n",
    "    with open(disc_split_file, \"w\") as out_f:\n",
    "        for i in range(curr_file_num):\n",
    "            curr_split_file = os.path.join(exp_local_path, disc_file_split_base.format(i))\n",
    "            split_cmd_out = split_cmd.format(\"out\", i)\n",
    "            #split_cmd_err = split_cmd.format(\"err\", i)\n",
    "            split_cmd_err = \"/dev/null\"\n",
    "\n",
    "            out_line = \"nice sh \"\n",
    "            out_f.write(full_split_cmd_string.format(curr_split_file, \\\n",
    "                                                    split_cmd_out, \\\n",
    "                                                    split_cmd_err))\n",
    "\n",
    "    print(\"Completed - disc.cmd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read transcripts, and translations into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_en_translations(file_list):\n",
    "    en_words = {}\n",
    "    with open(config[\"es\"][\"trans_file\"], \"r\") as in_f:\n",
    "        for fname, en_line in zip(file_list, in_f):\n",
    "            en_words[fname] = en_line.strip()\n",
    "    print(\"finished reading translations\")\n",
    "    pickle.dump(en_words, open(config[\"es\"][\"en_words\"], \"wb\"))\n",
    "    return en_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check English translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_english_translations():\n",
    "    en_w = []\n",
    "    [en_w.extend(w.split()) for w in list(en_words.values())]\n",
    "    en_words_freq = Counter(en_w)\n",
    "    print(sorted(en_words_freq.items(), reverse=True, key=lambda t:t[1])[:10])\n",
    "    print([(w,f) for w, f in en_words_freq.items() if \"'\" in w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing 1.085:   1%|          | 4/434 [00:00<00:11, 36.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Finished writing files.lst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing 1.175: 100%|██████████| 434/434 [00:10<00:00, 41.92it/s]\n",
      "processing 1: 100%|██████████| 10/10 [00:11<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed set test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_and_create_dirs()\n",
    "create_file_lst(config[\"es\"][\"lst_file\"])\n",
    "file_list = create_lsh_files()\n",
    "# file_list = read_file_list()\n",
    "# create_files_base(file_list)\n",
    "# create_discovery_cmd_scripts(num_splits=15)\n",
    "# en_words = read_en_translations(file_list[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "#     check_and_create_dirs()\n",
    "#     create_file_lst(config[\"es\"][\"lst_file\"])\n",
    "#     file_list = create_lsh_files()\n",
    "#     file_list = read_file_list()\n",
    "    create_files_base(file_list)\n",
    "    create_discovery_cmd_scripts(num_splits=15)\n",
    "#     en_words = read_en_translations(file_list[\"train\"])\n",
    "    print(\"maining\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_wavs():\n",
    "    train_test_str = \"test\"\n",
    "    dual_wav_path = \"../ainu/ainu-{0:s}-wavs/\".format(train_test_str)\n",
    "    mono_wav_path = \"../ainu/ainu-{0:s}-mono-wavs/\".format(train_test_str)\n",
    "    mono_8k_wav_path = \"../ainu/{0:s}-wavs/\".format(train_test_str)\n",
    "    \n",
    "    for wav_file in [f for f in os.listdir(dual_wav_path) if f.endswith(\".wav\")]:\n",
    "        #mono_wav_fname = wav_file.replace(\".mp3.SOX-CONVERTED.wav\", \".wav\")\n",
    "        mono_wav_fname = os.path.join(mono_wav_path, wav_file)\n",
    "        subprocess.call([config['base'][\"sox\"], os.path.join(dual_wav_path, wav_file), \n",
    "                         mono_wav_fname, \"remix\", \"1-2\"])\n",
    "    \n",
    "    for wav_file in [f for f in os.listdir(mono_wav_path) if f.endswith(\".wav\")]:\n",
    "        in_wav_fname = os.path.join(mono_wav_path, wav_file)\n",
    "        mono_8k_wav_fname = os.path.join(mono_8k_wav_path, wav_file)\n",
    "\n",
    "        subprocess.call([config['base'][\"sox\"], \"-t\", \"wav\", \n",
    "                         in_wav_fname, \"-t\", \"wav\", \"-e\", \"signed-integer\", \n",
    "                          \"-b\", \"16\", \"-c\", \"1\", \"-r\", \"8000\", \"--no-dither\", \n",
    "                         mono_8k_wav_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wavs = []\n",
    "# for f in os.listdir(config[\"es\"][\"train\"][\"wavs\"]):\n",
    "#     wavs.append(os.path.join(config[\"es\"][\"train\"][\"wavs\"], f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Audio(wavs[234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
