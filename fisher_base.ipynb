{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, \\\n",
    "     FormatStrFormatter, AutoMinorLocator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "\n",
    "# Gold feats\n",
    "gold_feats_dict_fname = config['es']['gold_feats']\n",
    "# Pseudo feats\n",
    "feats_dict_fname = config['es']['feats_dict_fname']\n",
    "\n",
    "gold_probs_fname = config['es']['mt_probs_gold']\n",
    "gold_probs_dict_fname = config['es']['mt_probs_dict_gold']\n",
    "\n",
    "pseudo_probs_fname = config['es']['mt_probs_pseudo']\n",
    "pseudo_probs_dict_fname = config['es']['mt_probs_dict_pseudo']\n",
    "\n",
    "train_segment_list_fname = config['es']['mt_train_files']\n",
    "dev_segment_list_fname = config['es']['mt_dev_files']\n",
    "\n",
    "gold_corpus_fname = config['es']['mt_corpus_train_gold']\n",
    "pseudo_corpus_fname = config['es']['mt_corpus_train_pseudo']\n",
    "\n",
    "mt_gold_pred_dict_fname = config['es']['mt_gold_pred_dict']\n",
    "mt_pseudo_pred_dict_fname = config['es']['mt_pseudo_pred_dict']\n",
    "\n",
    "mt_gold_eval_dict_fname = config['es']['mt_gold_eval_dict']\n",
    "mt_pseudo_eval_dict_fname = config['es']['mt_pseudo_eval_dict']\n",
    "\n",
    "es_merge_wavs_path = config['es']['es_merge_wavs']\n",
    "utd_wavs_path = config['es']['utd_wavs']\n",
    "\n",
    "utd_tmp_wav_path = config['es']['utd_wavs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])\n",
    "Eval = namedtuple('Eval', ['n1', 'n2', 'dtw', 'es_sim', 'es_cnt_sim', 'en_j_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))\n",
    "nodes_dict = pickle.load(open(nodes_dict_fname, \"rb\"))\n",
    "pairs_list = pickle.load(open(pairs_fname, \"rb\"))\n",
    "eval_dict = pickle.load(open(eval_fname, \"rb\"))\n",
    "clusters = pickle.load(open(clusters_fname, \"rb\"))\n",
    "clusters_stats = pickle.load(open(clusters_stats_fname, \"rb\"))\n",
    "feats_dict = pickle.load(open(feats_dict_fname, \"rb\"))\n",
    "gold_feats_dict = pickle.load(open(gold_feats_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(gold_probs_dict_fname):\n",
    "    gold_probs_dict = pickle.load(open(gold_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(pseudo_probs_dict_fname):\n",
    "    pseudo_probs_dict = pickle.load(open(pseudo_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(mt_gold_pred_dict_fname):\n",
    "    mt_gold_pred_dict = pickle.load(open(mt_gold_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_pred_dict_fname):\n",
    "    mt_pseudo_pred_dict = pickle.load(open(mt_pseudo_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_gold_eval_dict_fname):\n",
    "    mt_gold_eval_dict = pickle.load(open(mt_gold_eval_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_eval_dict_fname):\n",
    "    mt_pseudo_eval_dict = pickle.load(open(mt_pseudo_eval_dict_fname, \"rb\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fish_path = \"../../fisher/\"\n",
    "fish_flist_fname = \"../../fisher/goodfiles-gdfa.txt\"\n",
    "fish_es_align_path = os.path.join(fish_path, \"wav2es-word-final\")\n",
    "fish_subfolders = [os.path.join(fish_es_align_path, f) for f in map(str, range(8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es_words = [a.word for fid in align_dict for sid in align_dict[fid] for a in align_dict[fid][sid]['es']]\n",
    "es_cnt_words = [a.word for fid in align_dict for sid in align_dict[fid] for a in align_dict[fid][sid]['es_cnt']]\n",
    "en_words = [a.word for fid in align_dict for sid in align_dict[fid] for a in align_dict[fid][sid]['en']]\n",
    "en_cnt_words = [a.word for fid in align_dict for sid in align_dict[fid] for a in align_dict[fid][sid]['en_cnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168195 10674\n",
      "77134 10449\n",
      "159777 6723\n",
      "84466 6596\n"
     ]
    }
   ],
   "source": [
    "print(len(es_words), len(set(es_words)))\n",
    "print(len(es_cnt_words), len(set(es_cnt_words)))\n",
    "print(len(en_words), len(set(en_words)))\n",
    "print(len(en_cnt_words), len(set(en_cnt_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisher_get_details(transcript_path):\n",
    "    es_words = []\n",
    "    fids = []\n",
    "    dur = 0\n",
    "    dur_500ms = 0\n",
    "    for fname in [f for f in os.listdir(transcript_path) if f.endswith(\".es\")]:\n",
    "        fids.append(os.path.splitext(fname)[0].split(\"_\")[2])\n",
    "        with open(os.path.join(transcript_path, fname), \"r\") as in_f:\n",
    "            for line in in_f:\n",
    "                line_items = line.strip().split()\n",
    "                start, end = map(float, line_items[1:])\n",
    "                es_words.append(line_items[0])\n",
    "                curr_dur = end-start\n",
    "                dur += curr_dur\n",
    "                dur_500ms += curr_dur if curr_dur >= 0.5 else 0\n",
    "    print(\"finished\")\n",
    "    return es_words, fids, dur, dur_500ms\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "missing es: 7111\n",
      "dur, total: 14.56, 500ms: 4.69\n"
     ]
    }
   ],
   "source": [
    "# fish_es, fish_fids, fish_dur, fish_dur_500ms = fisher_get_details(fish_subfolders[0])\n",
    "fish_es = []\n",
    "fish_fids = set()\n",
    "fish_dur = 0\n",
    "fish_dur_500ms = 0\n",
    "for subfolder in fish_subfolders[2:3]:\n",
    "    temp_es, temp_fids, temp_dur, temp_dur_500ms = fisher_get_details(subfolder)\n",
    "    fish_es.extend(temp_es)\n",
    "    fish_fids |= set(temp_fids)\n",
    "    fish_dur += temp_dur\n",
    "    fish_dur_500ms += temp_dur_500ms\n",
    "    print(\"missing es: %d\" % len(set(es_words)-set(temp_es)))\n",
    "    print(\"dur, total: %.2f, 500ms: %.2f\" % (temp_dur / 3600, temp_dur_500ms / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#es: 180912, set: 9473, #fids: 116\n",
      "tots dur: 14.56, min 500ms dur: 4.69\n",
      "# es cnt: 9296,\n"
     ]
    }
   ],
   "source": [
    "fish_es_cnt = [w for w in list(set(fish_es)) if w.lower().decode(\"utf-8\") not in set(stopwords.words('spanish'))]\n",
    "    \n",
    "print(\"#es: %d, set: %d, #fids: %d\" % (len(fish_es), len(set(fish_es)), len(set(fish_fids))))\n",
    "print(\"tots dur: %.2f, min 500ms dur: %.2f\" %(fish_dur / 3600, fish_dur_500ms / 3600))\n",
    "print(\"# es cnt: %d,\" % (len(set(fish_es_cnt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing es\t7111, overlap: 33.4%\n",
      "missing es cnt\t7051\n"
     ]
    }
   ],
   "source": [
    "print(\"missing es\\t%d, overlap: %.1f%%\" % (len(set(es_words) - set(fish_es)), (len(set(es_words) & set(fish_es)) / len(set(es_words)) * 100)))\n",
    "print(\"missing es cnt\\t%d\" % len(set(es_cnt_words) - set(fish_es_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fish_fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20050908_191808_23_fsp_0_0020',\n",
       " '20050926_220244_130_fsp_0_0045',\n",
       " '20050909_221657_28_fsp_0_0086_plus',\n",
       " '20050908_182943_22_fsp_0_0026',\n",
       " '20050917_211045_76_fsp_0_0054']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.splitext(f)[0] for f in os.listdir(os.path.join(fish_es_align_path, \"0\"))[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
