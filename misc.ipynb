{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "from matplotlib.ticker import MultipleLocator, \\\n",
    "     FormatStrFormatter, AutoMinorLocator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "\n",
    "# Gold feats\n",
    "gold_feats_dict_fname = config['es']['gold_feats']\n",
    "# Pseudo feats\n",
    "feats_dict_fname = config['es']['feats_dict_fname']\n",
    "\n",
    "gold_probs_fname = config['es']['mt_probs_gold']\n",
    "gold_probs_dict_fname = config['es']['mt_probs_dict_gold']\n",
    "\n",
    "pseudo_probs_fname = config['es']['mt_probs_pseudo']\n",
    "pseudo_probs_dict_fname = config['es']['mt_probs_dict_pseudo']\n",
    "\n",
    "train_segment_list_fname = config['es']['mt_train_files']\n",
    "dev_segment_list_fname = config['es']['mt_dev_files']\n",
    "\n",
    "gold_corpus_fname = config['es']['mt_corpus_train_gold']\n",
    "pseudo_corpus_fname = config['es']['mt_corpus_train_pseudo']\n",
    "\n",
    "mt_gold_pred_dict_fname = config['es']['mt_gold_pred_dict']\n",
    "mt_pseudo_pred_dict_fname = config['es']['mt_pseudo_pred_dict']\n",
    "\n",
    "mt_gold_eval_dict_fname = config['es']['mt_gold_eval_dict']\n",
    "mt_pseudo_eval_dict_fname = config['es']['mt_pseudo_eval_dict']\n",
    "\n",
    "es_merge_wavs_path = config['es']['es_merge_wavs']\n",
    "utd_wavs_path = config['es']['utd_wavs']\n",
    "\n",
    "utd_tmp_wav_path = config['es']['utd_wavs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])\n",
    "Eval = namedtuple('Eval', ['n1', 'n2', 'dtw', 'es_sim', 'es_cnt_sim', 'en_j_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))\n",
    "nodes_dict = pickle.load(open(nodes_dict_fname, \"rb\"))\n",
    "pairs_list = pickle.load(open(pairs_fname, \"rb\"))\n",
    "eval_dict = pickle.load(open(eval_fname, \"rb\"))\n",
    "clusters = pickle.load(open(clusters_fname, \"rb\"))\n",
    "clusters_stats = pickle.load(open(clusters_stats_fname, \"rb\"))\n",
    "feats_dict = pickle.load(open(feats_dict_fname, \"rb\"))\n",
    "gold_feats_dict = pickle.load(open(gold_feats_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(gold_probs_dict_fname):\n",
    "    gold_probs_dict = pickle.load(open(gold_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(pseudo_probs_dict_fname):\n",
    "    pseudo_probs_dict = pickle.load(open(pseudo_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(mt_gold_pred_dict_fname):\n",
    "    mt_gold_pred_dict = pickle.load(open(mt_gold_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_pred_dict_fname):\n",
    "    mt_pseudo_pred_dict = pickle.load(open(mt_pseudo_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_gold_eval_dict_fname):\n",
    "    mt_gold_eval_dict = pickle.load(open(mt_gold_eval_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_eval_dict_fname):\n",
    "    mt_pseudo_eval_dict = pickle.load(open(mt_pseudo_eval_dict_fname, \"rb\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev set split between calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_factor = 10\n",
    "start_fid = 81\n",
    "end_fid = 120\n",
    "train_fname = \"../files-train-segments-sf-%d.txt\" % split_factor\n",
    "dev_fname = \"../files-dev-segments-sf-%d.txt\" % split_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"031\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_segment_level_sets(t_fname, d_fname, start_fid, end_fid, split_factor):\n",
    "    if split_factor == 0:\n",
    "        print(\"Invalid split factor\")\n",
    "        return\n",
    "    print(\"creating %s, %s\" %(t_fname, d_fname))\n",
    "    s_fid = \"%03d\" % start_fid\n",
    "    e_fid = \"%03d\" % end_fid\n",
    "    \n",
    "    sel_fids = sorted([fid for fid in align_dict.keys() if \\\n",
    "                int(fid) >= start_fid and int(fid) <= end_fid])\n",
    "    \n",
    "    t_count = 0\n",
    "    d_count = 0\n",
    "\n",
    "    with open(train_fname, \"w\") as t_f, open(dev_fname, \"w\") as d_f:\n",
    "        for fid in sel_fids:\n",
    "            sids = align_dict[fid].keys()\n",
    "            dev_num = len(sids) // split_factor\n",
    "            random.shuffle(sids)\n",
    "            dev_sids = sids[:dev_num]\n",
    "            train_sids = sids[dev_num:]\n",
    "            t_count += len(train_sids)\n",
    "            d_count += len(dev_sids)\n",
    "            d_f.write('\\n'.join(dev_sids))\n",
    "            d_f.write('\\n')\n",
    "            t_f.write('\\n'.join(train_sids))\n",
    "            t_f.write('\\n')\n",
    "    print(t_count, d_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sel_fids = sorted([fid for fid in align_dict.keys() if \\\n",
    "#                 int(fid) >= start_fid and int(fid) <= end_fid])\n",
    "\n",
    "# sids = align_dict['001'].keys()\n",
    "# dev_num = len(sids) // split_factor\n",
    "# print(dev_num)\n",
    "# random.shuffle(sids)\n",
    "# dev_sids = sids[:dev_num]\n",
    "# train_sids = sids[dev_num:]\n",
    "# print(','.join(dev_sids))\n",
    "# print('\\n')\n",
    "# print(','.join(train_sids))\n",
    "# print('\\n')\n",
    "# print(len(train_sids), len(dev_sids))\n",
    "# len(sel_fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../files-train-segments-sf-10.txt, ../files-dev-segments-sf-10.txt\n",
      "5930 639\n"
     ]
    }
   ],
   "source": [
    "create_segment_level_sets(train_fname, dev_fname, start_fid, end_fid, split_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'../files-train-segments-sf-10.txt', u'../files-dev-segments-sf-10.txt')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_list_fname, dev_segment_list_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fids = []\n",
    "train_sids = []\n",
    "with open(train_segment_list_fname, \"r\") as in_f:\n",
    "    for line in in_f:\n",
    "        train_fids.append(line.strip().split(\".\")[0])\n",
    "        train_sids.append(line.strip())\n",
    "train_fids = set(train_fids)\n",
    "train_sids = set(train_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_fids = []\n",
    "dev_sids = []\n",
    "with open(dev_segment_list_fname, \"r\") as in_f:\n",
    "    for line in in_f:\n",
    "        dev_fids.append(line.strip().split(\".\")[0])\n",
    "        dev_sids.append(line.strip())\n",
    "dev_fids = set(dev_fids)\n",
    "dev_sids = set(dev_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters_stats['is_dev'] = []\n",
    "clusters_stats['is_train'] = []\n",
    "clusters_stats['oov'] = []\n",
    "for sids in clusters_stats['sids']:\n",
    "    is_in_dev = len(dev_sids & set(sids)) > 0\n",
    "    is_in_train = len(train_sids & set(sids)) > 0\n",
    "    clusters_stats['is_dev'].append(is_in_dev)\n",
    "    clusters_stats['is_train'].append(is_in_train)\n",
    "    clusters_stats['oov'].append(is_in_dev and not is_in_train)\n",
    "\n",
    "clusters_stats['dev_depth'] = []\n",
    "clusters_stats['train_depth'] = []\n",
    "for nlist in clusters_stats['sids']:\n",
    "    clusters_stats['dev_depth'].append(len([i for i in nlist if i in dev_sids]))\n",
    "    clusters_stats['train_depth'].append(len([i for i in nlist if i in train_sids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "620\n",
      "2674\n"
     ]
    }
   ],
   "source": [
    "num_oov = sum([i for i in clusters_stats['oov']])\n",
    "print(num_oov)\n",
    "sum_oov = sum([d for i, d in enumerate(clusters_stats['dev_depth']) if clusters_stats['oov'][i]])\n",
    "total_pwords = sum([d for i, d in enumerate(clusters_stats['dev_depth']) if clusters_stats['is_dev'][i]])\n",
    "print(sum_oov)\n",
    "print(total_pwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+---------+---------------+\n",
      "| Total words | oov | Missing | oov + missing |\n",
      "+-------------+-----+---------+---------------+\n",
      "|     3324    | 620 |   650   |      1270     |\n",
      "+-------------+-----+---------+---------------+\n",
      "+-------------+-----------+\n",
      "| total vocab | oov vocab |\n",
      "+-------------+-----------+\n",
      "|     2335    |    511    |\n",
      "+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "dev_pwords = []\n",
    "train_pwords = []\n",
    "oov_pwords = []\n",
    "for did in dev_sids:\n",
    "    dev_pwords.extend(feats_dict[did])\n",
    "for tid in train_sids:\n",
    "    train_pwords.extend(feats_dict[tid])\n",
    "set_train_pwords = set(train_pwords)\n",
    "oov_pwords = [cid for cid in dev_pwords if cid not in set_train_pwords and cid != \"-1\"]\n",
    "missing_words = [i for cid in dev_pwords if cid == \"-1\"]\n",
    "out_line = PrettyTable([\"Total words\", \"oov\", \"Missing\", \"oov + missing\"])\n",
    "out_line.add_row([len(dev_pwords), len(oov_pwords), \\\n",
    "                  len(missing_words), \\\n",
    "                 len(oov_pwords) + len(missing_words)])\n",
    "print(out_line)\n",
    "\n",
    "out_line = PrettyTable([\"total vocab\", \"oov vocab\"])\n",
    "out_line.add_row([len(set(dev_pwords)), len(set(oov_pwords))])\n",
    "print(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+---------+---------------+\n",
      "| Total words | oov  | Missing | oov + missing |\n",
      "+-------------+------+---------+---------------+\n",
      "|     3324    | 1270 |   650   |      1920     |\n",
      "+-------------+------+---------+---------------+\n",
      "+-------------+-----------+\n",
      "| total vocab | oov vocab |\n",
      "+-------------+-----------+\n",
      "|     2335    |    512    |\n",
      "+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "dev_pwords = []\n",
    "train_pwords = []\n",
    "oov_pwords = []\n",
    "for did in dev_sids:\n",
    "    dev_pwords.extend(feats_dict[did])\n",
    "for tid in train_sids:\n",
    "    train_pwords.extend(feats_dict[tid])\n",
    "set_train_pwords = set(train_pwords)\n",
    "oov_pwords = [cid for cid in dev_pwords if cid not in set_train_pwords or cid == \"-1\"]\n",
    "out_line = PrettyTable([\"Total words\", \"oov\", \"Missing\", \"oov + missing\"])\n",
    "out_line.add_row([len(dev_pwords), len(oov_pwords), \\\n",
    "                  len([i for i in dev_pwords if i == \"-1\"]), \\\n",
    "                 len(oov_pwords) + len([i for i in dev_pwords if i == \"-1\"])])\n",
    "print(out_line)\n",
    "\n",
    "out_line = PrettyTable([\"total vocab\", \"oov vocab\"])\n",
    "out_line.add_row([len(set(dev_pwords)), len(set(oov_pwords))])\n",
    "print(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324, 2674, 2334)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_pwords), len([i for i in dev_pwords if i != '-1']), len(set([i for i in dev_pwords if i != '-1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pseudo_mt_eval_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b45539727e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpseudo_mt_eval_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pseudo_mt_eval_dict' is not defined"
     ]
    }
   ],
   "source": [
    "pseudo_mt_eval_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
