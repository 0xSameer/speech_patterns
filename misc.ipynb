{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "from matplotlib.ticker import MultipleLocator, \\\n",
    "     FormatStrFormatter, AutoMinorLocator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "\n",
    "# Gold feats\n",
    "gold_feats_dict_fname = config['es']['gold_feats']\n",
    "# Pseudo feats\n",
    "feats_dict_fname = config['es']['feats_dict_fname']\n",
    "\n",
    "gold_probs_fname = config['es']['mt_probs_gold']\n",
    "gold_probs_dict_fname = config['es']['mt_probs_dict_gold']\n",
    "\n",
    "pseudo_probs_fname = config['es']['mt_probs_pseudo']\n",
    "pseudo_probs_dict_fname = config['es']['mt_probs_dict_pseudo']\n",
    "\n",
    "train_segment_list_fname = config['es']['mt_train_files']\n",
    "dev_segment_list_fname = config['es']['mt_dev_files']\n",
    "\n",
    "gold_corpus_fname = config['es']['mt_corpus_train_gold']\n",
    "pseudo_corpus_fname = config['es']['mt_corpus_train_pseudo']\n",
    "\n",
    "mt_gold_pred_dict_fname = config['es']['mt_gold_pred_dict']\n",
    "mt_pseudo_pred_dict_fname = config['es']['mt_pseudo_pred_dict']\n",
    "\n",
    "mt_gold_eval_dict_fname = config['es']['mt_gold_eval_dict']\n",
    "mt_pseudo_eval_dict_fname = config['es']['mt_pseudo_eval_dict']\n",
    "\n",
    "es_merge_wavs_path = config['es']['es_merge_wavs']\n",
    "utd_wavs_path = config['es']['utd_wavs']\n",
    "\n",
    "utd_tmp_wav_path = config['es']['utd_wavs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])\n",
    "Eval = namedtuple('Eval', ['n1', 'n2', 'dtw', 'es_sim', 'es_cnt_sim', 'en_j_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))\n",
    "nodes_dict = pickle.load(open(nodes_dict_fname, \"rb\"))\n",
    "pairs_list = pickle.load(open(pairs_fname, \"rb\"))\n",
    "eval_dict = pickle.load(open(eval_fname, \"rb\"))\n",
    "clusters = pickle.load(open(clusters_fname, \"rb\"))\n",
    "clusters_stats = pickle.load(open(clusters_stats_fname, \"rb\"))\n",
    "feats_dict = pickle.load(open(feats_dict_fname, \"rb\"))\n",
    "gold_feats_dict = pickle.load(open(gold_feats_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(gold_probs_dict_fname):\n",
    "    gold_probs_dict = pickle.load(open(gold_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(pseudo_probs_dict_fname):\n",
    "    pseudo_probs_dict = pickle.load(open(pseudo_probs_dict_fname, \"rb\"))\n",
    "\n",
    "if os.path.exists(mt_gold_pred_dict_fname):\n",
    "    mt_gold_pred_dict = pickle.load(open(mt_gold_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_pred_dict_fname):\n",
    "    mt_pseudo_pred_dict = pickle.load(open(mt_pseudo_pred_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_gold_eval_dict_fname):\n",
    "    mt_gold_eval_dict = pickle.load(open(mt_gold_eval_dict_fname, \"rb\"))\n",
    "    \n",
    "if os.path.exists(mt_pseudo_eval_dict_fname):\n",
    "    mt_pseudo_eval_dict = pickle.load(open(mt_pseudo_eval_dict_fname, \"rb\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev set split between calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_factor = 10\n",
    "start_fid = 63\n",
    "end_fid = 120\n",
    "train_fname = \"../files-train-segments-%d-%d-%d.txt\" % (start_fid, end_fid, split_factor)\n",
    "dev_fname = \"../files-dev-segments-%d-%d-%d.txt\" % (start_fid, end_fid, split_factor)\n",
    "train_call_fname = \"../files-train-calls-%d-%d-%d.txt\" % (start_fid, end_fid, split_factor)\n",
    "dev_call_fname = \"../files-dev-calls-%d-%d-%d.txt\" % (start_fid, end_fid, split_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': [Align(word='MECHITA', start=12, end=50),\n",
       "  Align(word='WHAT', start=50, end=73),\n",
       "  Align(word='SENT', start=129, end=169),\n",
       "  Align(word='IT', start=126, end=129),\n",
       "  Align(word='TO', start=169, end=176),\n",
       "  Align(word='WHOM', start=176, end=192),\n",
       "  Align(word='TO', start=192, end=198),\n",
       "  Align(word='POCHO', start=198, end=225)],\n",
       " 'en_cnt': [Align(word='MECHITA', start=12, end=50),\n",
       "  Align(word='SENT', start=129, end=169),\n",
       "  Align(word='POCHO', start=198, end=225)],\n",
       " 'es': [Align(word='MECHITA', start=12, end=50),\n",
       "  Align(word='QU\\xc3\\xa9', start=50, end=73),\n",
       "  Align(word='LAS', start=109, end=126),\n",
       "  Align(word='HA', start=126, end=129),\n",
       "  Align(word='MANDADO', start=129, end=169),\n",
       "  Align(word='A', start=169, end=176),\n",
       "  Align(word='QUI\\xc3\\xa9N', start=176, end=192),\n",
       "  Align(word='A', start=192, end=198),\n",
       "  Align(word='POCHO', start=198, end=225)],\n",
       " 'es_cnt': [Align(word='MECHITA', start=12, end=50),\n",
       "  Align(word='MANDADO', start=129, end=169),\n",
       "  Align(word='QUI\\xc3\\xa9N', start=176, end=192),\n",
       "  Align(word='POCHO', start=198, end=225)]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_dict['001']['001.001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_segment_level_sets(t_fname, d_fname, start_fid, end_fid, split_factor):\n",
    "    if split_factor == 0:\n",
    "        print(\"Invalid split factor\")\n",
    "        return\n",
    "    print(\"creating %s, %s\" %(t_fname, d_fname))\n",
    "    s_fid = \"%03d\" % start_fid\n",
    "    e_fid = \"%03d\" % end_fid\n",
    "    \n",
    "    sel_fids = sorted([fid for fid in align_dict.keys() if \\\n",
    "                int(fid) >= start_fid and int(fid) <= end_fid])\n",
    "    \n",
    "    t_count = 0\n",
    "    d_count = 0\n",
    "    t_dur = 0\n",
    "    d_dur = 0\n",
    "\n",
    "    with open(train_fname, \"w\") as t_f, open(dev_fname, \"w\") as d_f:\n",
    "        for fid in sel_fids:\n",
    "            sids = align_dict[fid].keys()\n",
    "            dev_num = len(sids) // split_factor\n",
    "            random.shuffle(sids)\n",
    "            dev_sids = sids[:dev_num]\n",
    "            d_dur += sum([(a.end-a.start) for s in dev_sids for a in align_dict[fid][s]['es']])\n",
    "            train_sids = sids[dev_num:]\n",
    "            t_dur += sum([(a.end-a.start) for s in train_sids for a in align_dict[fid][s]['es']])\n",
    "            t_count += len(train_sids)\n",
    "            d_count += len(dev_sids)\n",
    "            d_f.write('\\n'.join(dev_sids))\n",
    "            d_f.write('\\n')\n",
    "            t_f.write('\\n'.join(train_sids))\n",
    "            t_f.write('\\n')\n",
    "    print(t_count, d_count)\n",
    "    print(\"training: %0.2f (hrs), dev: %0.2f (hrs)\" %((t_dur/100/3600), (d_dur/100/3600)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_call_level_sets(t_fname, d_fname, start_fid, end_fid, split_factor):\n",
    "    if split_factor == 0:\n",
    "        print(\"Invalid split factor\")\n",
    "        return\n",
    "    print(\"creating %s, %s\" %(t_fname, d_fname))\n",
    "    s_fid = \"%03d\" % start_fid\n",
    "    e_fid = \"%03d\" % end_fid\n",
    "    \n",
    "    sel_fids = sorted([fid for fid in align_dict.keys() if \\\n",
    "                int(fid) >= start_fid and int(fid) <= end_fid])\n",
    "    \n",
    "    random.shuffle(sel_fids)\n",
    "    \n",
    "    t_count = 0\n",
    "    d_count = 0\n",
    "    \n",
    "    t_fids = []\n",
    "    d_fids = []\n",
    "    t_dur = 0\n",
    "    d_dur = 0\n",
    "\n",
    "    with open(train_fname, \"w\") as t_f, open(dev_fname, \"w\") as d_f:\n",
    "        for i, fid in enumerate(sel_fids):\n",
    "            sids = align_dict[fid].keys()\n",
    "            if i < len(sel_fids) // split_factor:\n",
    "                d_count += len(sids)\n",
    "                d_f.write('\\n'.join(sids))\n",
    "                d_f.write('\\n')\n",
    "                d_dur += sum([(a.end-a.start) for s in sids for a in align_dict[fid][s]['es']])\n",
    "                d_fids.append(fid)\n",
    "            else:\n",
    "                t_count += len(sids)\n",
    "                t_f.write('\\n'.join(sids))\n",
    "                t_f.write('\\n')\n",
    "                t_dur += sum([(a.end-a.start) for s in sids for a in align_dict[fid][s]['es']])\n",
    "                t_fids.append(fid)\n",
    "    print(t_count, d_count)\n",
    "    print(\"training: %0.2f (hrs), dev: %0.2f (hrs)\" %((t_dur/100/3600), (d_dur/100/3600)))\n",
    "    print(\"# files training: %d, test: %d\" %(len(t_fids), len(d_fids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([fid for fid in align_dict.keys() if int(fid) >= 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../files-train-segments-63-120-10.txt',\n",
       " '../files-dev-segments-63-120-10.txt')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname, dev_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../files-train-segments-63-120-10.txt, ../files-dev-segments-63-120-10.txt\n",
      "8094 872\n",
      "training: 6.06 (hrs), dev: 0.63 (hrs)\n"
     ]
    }
   ],
   "source": [
    "create_segment_level_sets(train_fname, dev_fname, start_fid, end_fid, split_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../files-train-calls-63-120-10.txt, ../files-dev-calls-63-120-10.txt\n",
      "8188 778\n",
      "training: 6.03 (hrs), dev: 0.66 (hrs)\n",
      "# files training: 45, test: 5\n"
     ]
    }
   ],
   "source": [
    "create_call_level_sets(train_call_fname, dev_call_fname, start_fid, end_fid, split_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'../files-train-segments-1-120-10.txt',\n",
       " u'../files-dev-segments-1-120-10.txt')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_list_fname, dev_segment_list_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
