{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import bisect\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    config = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_fname = config[\"es\"]['nodes_fname']\n",
    "seg_nodes_fname = config[\"es\"]['seg_nodes_fname']\n",
    "nodes_dict_fname = config[\"es\"]['nodes_dict_fname']\n",
    "\n",
    "edges_utd_fname = config[\"es\"]['edges_utd_fname']\n",
    "edges_olap_fname = config[\"es\"]['edges_olap_fname']\n",
    "edges_all_fname = config[\"es\"]['edges_all_fname']\n",
    "edges_score_fname = config[\"es\"]['edges_score_fname']\n",
    "\n",
    "clusters_utd_fname = config['es']['clusters_utd_fname']\n",
    "clusters_fname = config['es']['clusters_fname']\n",
    "clusters_stats_fname = config['es']['clusters_stats_fname']\n",
    "\n",
    "pairs_fname = config['es']['score_pairs_fname']\n",
    "eval_fname = config['es']['eval_pairs_fname']\n",
    "\n",
    "feats_fname = config['es']['feats_fname']\n",
    "feats_dict_fname = config['es']['feats_dict_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Align = namedtuple('Align', ['word', 'start', 'end'])\n",
    "Node = namedtuple('Node', ['file', 'seg', 'start', 'end', 'es', 'es_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Eval = namedtuple('Eval', ['n1', 'n2', 'dtw', 'es_sim', 'es_cnt_sim', 'en_j_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_map = pickle.load(open(config['es']['segment_dict_fname'], \"rb\"))\n",
    "align_dict = pickle.load(open(config['es']['align_dict_fname'], \"rb\"))\n",
    "nodes_dict = pickle.load(open(nodes_dict_fname, \"rb\"))\n",
    "pairs_list = pickle.load(open(pairs_fname, \"rb\"))\n",
    "clusters = pickle.load(open(clusters_fname, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all valid pairs discovered\n",
    "\n",
    "- Calculate es sim, es content word sim, en content word sim\n",
    "- Calculate num correct pairs, num total, num content correct, at D=80, and D=87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_jaccard(w_list1, w_list2):\n",
    "    common_keys = set(w_list1) & set(w_list2)\n",
    "    union_keys = set(w_list1) | set(w_list2)\n",
    "    jaccard_dist = (0 if len(union_keys) == 0 else len(common_keys) / len(union_keys))\n",
    "    return jaccard_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_match_any(w_list1, w_list2):\n",
    "    common_words_len = len(set(w_list1) & set(w_list2))\n",
    "    return max(min(1, common_words_len), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_utd_pairs(pairs_list, nodes_dict, segment_map, eval_fname):\n",
    "    eval_list = []\n",
    "    \n",
    "    display_den = int(len(pairs_list) / 10)\n",
    "    \n",
    "    for pair_num, pair in enumerate(pairs_list, start=1):\n",
    "        \n",
    "        if pair_num % display_den == 0:\n",
    "            print(\"Evluating pair number: %d\" % pair_num)\n",
    "            \n",
    "        n1_id = pair[0]\n",
    "        n2_id = pair[1]\n",
    "        n1 = nodes_dict[pair[0]]\n",
    "        n2 = nodes_dict[pair[1]]\n",
    "        dtw = pair[2]\n",
    "        \n",
    "        es_sim = similarity_match_any(n1.es, n2.es)\n",
    "        es_cnt_sim = similarity_match_any(n1.es_cnt, n2.es_cnt)\n",
    "        \n",
    "        en_n1 = [a.word for a in align_dict[n1.file][n1.seg]['en_cnt']]\n",
    "        en_n2 = [a.word for a in align_dict[n2.file][n2.seg]['en_cnt']]\n",
    "        en_j_sim = similarity_jaccard(en_n1, en_n2)\n",
    "        \n",
    "        #eval_dict[pair_num] = Eval(n1_id, n2_id, dtw, es_sim, es_cnt_sim, en_j_sim)\n",
    "        eval_list.append(Eval(n1_id, n2_id, dtw, es_sim, es_cnt_sim, en_j_sim))\n",
    "    \n",
    "    # Saving eval\n",
    "    pickle.dump(eval_list, open(eval_fname, \"wb\"))\n",
    "    print(\"Finished evaluating %d pairs\" % pair_num)\n",
    "    return eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evluating pair number: 1337\n",
      "Evluating pair number: 2674\n",
      "Evluating pair number: 4011\n",
      "Evluating pair number: 5348\n",
      "Evluating pair number: 6685\n",
      "Evluating pair number: 8022\n",
      "Evluating pair number: 9359\n",
      "Evluating pair number: 10696\n",
      "Evluating pair number: 12033\n",
      "Evluating pair number: 13370\n",
      "Finished evaluating 13370 pairs\n"
     ]
    }
   ],
   "source": [
    "eval_list = eval_utd_pairs(pairs_list, nodes_dict, segment_map, eval_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_dict, columns=Eval._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs evaluated: 13370\n",
      "pairs with es word match: 4000\n",
      "pairs with es content word match: 2559\n",
      "pairs with D >= 0.87: 10164\n",
      "pairs with es word match: 3393\n",
      "pairs with es content word match: 2304\n"
     ]
    }
   ],
   "source": [
    "# All matches\n",
    "print('Total pairs evaluated: %d' % len(eval_list))\n",
    "\n",
    "es_match = [i for i, e in enumerate(eval_list) if e.es_sim == 1]\n",
    "es_cnt_match = [i for i, e in enumerate(eval_list) if e.es_cnt_sim == 1]\n",
    "print('pairs with es word match: %d' % len(es_match))\n",
    "print('pairs with es content word match: %d' % len(es_cnt_match))\n",
    "\n",
    "# D=0.87\n",
    "es_87_pairs = [i for i, e in enumerate(eval_list) if e.dtw >= 0.88]\n",
    "es_87_match = [i for i, e in enumerate(eval_list) if e.es_sim == 1 and e.dtw >= 0.88]\n",
    "es_87_cnt_match = [i for i, e in enumerate(eval_list) if e.es_cnt_sim == 1 and e.dtw >= 0.88]\n",
    "print('pairs with D >= 0.87: %d' % len(es_87_pairs))\n",
    "print('pairs with es word match: %d' % len(es_87_match))\n",
    "print('pairs with es content word match: %d' % len(es_87_cnt_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters\n",
    "\n",
    "- calculate cluster purity, and most common word\n",
    "- generate features, parallel corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cluster_stats(clusters, nodes_dict):\n",
    "    cluster_stats = {'words':[], 'purity':[], 'most_common':[], 'avg_purity':0.0}\n",
    "    avg_purity_num = 0\n",
    "    avg_purity_den = 0\n",
    "    for i, nodes in enumerate(clusters):\n",
    "        cnt_words = []\n",
    "        for node in nodes:\n",
    "            cnt_words.extend(list(nodes_dict[node].es_cnt))\n",
    "        cnt_words = [w.lower().decode(\"utf-8\") for w in cnt_words]\n",
    "        cluster_stats['words'].append(cnt_words)\n",
    "        counter_words = Counter(cnt_words)\n",
    "        most_common_word = counter_words.most_common(1)[0] if len(cnt_words) > 0 else (': (', 0)\n",
    "        #print(i, most_common_word)\n",
    "        cluster_stats['most_common'].append(most_common_word[0])\n",
    "        temp_len = len(cnt_words) if len(cnt_words) > 0 else 1\n",
    "        cluster_stats['purity'].append(most_common_word[1] / (temp_len * 1.0))\n",
    "        avg_purity_num += most_common_word[1]\n",
    "        avg_purity_den += temp_len\n",
    "    cluster_stats['avg_purity'] = avg_purity_num / avg_purity_den\n",
    "    print('Finished calculation cluster stats')\n",
    "    print('Average cluster purity: %0.3f' % cluster_stats['avg_purity'])\n",
    "    pickle.dump(cluster_stats, open(clusters_stats_fname, \"wb\"))\n",
    "    return cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculation cluster stats\n",
      "Average cluster purity: 0.373\n"
     ]
    }
   ],
   "source": [
    "clusters_stats = calc_cluster_stats(clusters, nodes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of pseudowords\n",
    "\n",
    "- For each segment, generate a bag of cluster ids based on the nodes discovered\n",
    "- default cluster id: -1 when no nodes found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
